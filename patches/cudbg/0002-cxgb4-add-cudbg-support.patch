From 2ff94039a9dc28b3709bd9fa389129f66cf7ecd5 Mon Sep 17 00:00:00 2001
From: Rahul Lakkireddy <rahul.lakkireddy@chelsio.com>
Date: Tue, 7 Nov 2017 19:34:38 +0530
Subject: [PATCH 2/3] cxgb4: add cudbg support

Add support to collect cudbg debug logs from cxgb4.

Signed-off-by: Rahul Lakkireddy <rahul.lakkireddy@chelsio.com>
---
 drivers/net/ethernet/chelsio/cxgb4/Makefile        |    3 +-
 drivers/net/ethernet/chelsio/cxgb4/cudbg_common.c  |   26 +-
 drivers/net/ethernet/chelsio/cxgb4/cudbg_entity.h  |  187 ++
 .../net/ethernet/chelsio/cxgb4/cudbg_flash_utils.c |  241 +++
 drivers/net/ethernet/chelsio/cxgb4/cudbg_if.h      |   66 +
 drivers/net/ethernet/chelsio/cxgb4/cudbg_lib.c     | 1792 ++++++++++++++++++--
 drivers/net/ethernet/chelsio/cxgb4/cudbg_lib.h     |   80 +
 .../net/ethernet/chelsio/cxgb4/cudbg_lib_common.h  |   36 +-
 drivers/net/ethernet/chelsio/cxgb4/cxgb4_cudbg.c   |  241 ++-
 drivers/net/ethernet/chelsio/cxgb4/cxgb4_cudbg.h   |    1 +
 drivers/net/ethernet/chelsio/cxgb4/fastlz.c        |  328 ++++
 drivers/net/ethernet/chelsio/cxgb4/fastlz.h        |   88 +
 drivers/net/ethernet/chelsio/cxgb4/fastlz_api.c    |  176 ++
 drivers/net/ethernet/chelsio/cxgb4/fastlz_common.h |  134 ++
 14 files changed, 3270 insertions(+), 129 deletions(-)
 create mode 100644 drivers/net/ethernet/chelsio/cxgb4/cudbg_flash_utils.c
 create mode 100644 drivers/net/ethernet/chelsio/cxgb4/fastlz.c
 create mode 100644 drivers/net/ethernet/chelsio/cxgb4/fastlz.h
 create mode 100644 drivers/net/ethernet/chelsio/cxgb4/fastlz_api.c
 create mode 100644 drivers/net/ethernet/chelsio/cxgb4/fastlz_common.h

diff --git a/drivers/net/ethernet/chelsio/cxgb4/Makefile b/drivers/net/ethernet/chelsio/cxgb4/Makefile
index 5414a7de..f4423026 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/Makefile
+++ b/drivers/net/ethernet/chelsio/cxgb4/Makefile
@@ -6,7 +6,8 @@ obj-$(CONFIG_CHELSIO_T4) += cxgb4.o
 
 cxgb4-objs := cxgb4_main.o l2t.o t4_hw.o sge.o clip_tbl.o cxgb4_ethtool.o \
 	      cxgb4_cudbg.o \
-	      cudbg_common.o cudbg_lib.o
+	      cudbg_common.o cudbg_lib.o \
+	      cudbg_flash_utils.o fastlz_api.o fastlz.o
 cxgb4-$(CONFIG_CHELSIO_T4_DCB) +=  cxgb4_dcb.o
 cxgb4-$(CONFIG_CHELSIO_T4_UWIRE) +=  cxgb4_ppm.o
 cxgb4-$(CONFIG_DEBUG_FS) += cxgb4_debugfs.o
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cudbg_common.c b/drivers/net/ethernet/chelsio/cxgb4/cudbg_common.c
index f78ba174..0543c35e 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cudbg_common.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cudbg_common.c
@@ -18,8 +18,10 @@
 #include "cxgb4.h"
 #include "cudbg_if.h"
 #include "cudbg_lib_common.h"
+#include "fastlz_common.h"
 
-int cudbg_get_buff(struct cudbg_buffer *pdbg_buff, u32 size,
+int cudbg_get_buff(struct cudbg_init *pdbg_init,
+		   struct cudbg_buffer *pdbg_buff, u32 size,
 		   struct cudbg_buffer *pin_buff)
 {
 	u32 offset;
@@ -28,17 +30,35 @@ int cudbg_get_buff(struct cudbg_buffer *pdbg_buff, u32 size,
 	if (offset + size > pdbg_buff->size)
 		return CUDBG_STATUS_NO_MEM;
 
+	if (pdbg_init->compress_type != CUDBG_COMPRESSION_NONE) {
+		pin_buff->data = (char *)pdbg_init->compress_buff;
+		pin_buff->offset = 0;
+		pin_buff->size = size;
+		return 0;
+	}
+
 	pin_buff->data = (char *)pdbg_buff->data + offset;
 	pin_buff->offset = offset;
 	pin_buff->size = size;
-	pdbg_buff->size -= size;
 	return 0;
 }
 
+void cudbg_get_compress_buff(struct cudbg_init *pdbg_init,
+			     struct cudbg_buffer *pdbg_buff,
+			     struct cudbg_buffer *pin_buff)
+{
+	/* There is at least CUDBG_BLOCK_SIZE extra reserved for
+	 * compression result during pdbg_init->compress_buff
+	 * allocation.  So, we can never run out of space.
+	 */
+	pin_buff->data = (char *)pdbg_init->compress_buff + pdbg_buff->size;
+	pin_buff->offset = pdbg_buff->size;
+	pin_buff->size = CUDBG_BLOCK_SIZE;
+}
+
 void cudbg_put_buff(struct cudbg_buffer *pin_buff,
 		    struct cudbg_buffer *pdbg_buff)
 {
-	pdbg_buff->size += pin_buff->size;
 	pin_buff->data = NULL;
 	pin_buff->offset = 0;
 	pin_buff->size = 0;
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cudbg_entity.h b/drivers/net/ethernet/chelsio/cxgb4/cudbg_entity.h
index 239c4308..f00f1b0b 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cudbg_entity.h
+++ b/drivers/net/ethernet/chelsio/cxgb4/cudbg_entity.h
@@ -18,14 +18,25 @@
 #ifndef __CUDBG_ENTITY_H__
 #define __CUDBG_ENTITY_H__
 
+#define MC0_FLAG 1
+#define MC1_FLAG 2
 #define EDC0_FLAG 3
 #define EDC1_FLAG 4
+#define HMA_FLAG 5
+
+#define CUDBG_NUM_PCIE_CONFIG_REGS 0x61
+
+#define CUDBG_PORT_TYPE_ADDR 0x1869
+#define CUDBG_PORT_TYPE_LEN 8
 
 #define CUDBG_ENTITY_SIGNATURE 0xCCEDB001
 
 struct card_mem {
+	u16 size_mc0;
+	u16 size_mc1;
 	u16 size_edc0;
 	u16 size_edc1;
+	u16 size_hma;
 	u16 mem_flag;
 };
 
@@ -44,11 +55,35 @@ struct cudbg_cim_qcfg {
 	u32 stat[4 * (CIM_NUM_IBQ + CIM_NUM_OBQ_T5)];
 };
 
+struct cudbg_rss_pf_conf {
+	u32 rss_pf_map;
+	u32 rss_pf_mask;
+	u32 rss_pf_config;
+};
+
 struct cudbg_rss_vf_conf {
 	u32 rss_vf_vfl;
 	u32 rss_vf_vfh;
 };
 
+struct cudbg_rss_config {
+	u32 tp_rssconf; /* TP_RSS_CONFIG_A */
+	u32 tp_rssconf_tnl; /* TP_RSS_CONFIG_TNL_A */
+	u32 tp_rssconf_ofd; /* TP_RSS_CONFIG_OFD_A */
+	u32 tp_rssconf_syn; /* TP_RSS_CONFIG_SYN_A */
+	u32 tp_rssconf_vrt; /* TP_RSS_CONFIG_VRT_A */
+	u32 tp_rssconf_cng; /* TP_RSS_CONFIG_CNG_A */
+	u32 chip;
+};
+
+struct cudbg_sw_state {
+	u32 fw_state;
+	u8 caller_string[100];
+	u8 os_type;
+	u8 reserved[3];
+	u32 reserved1[16];
+};
+
 struct cudbg_pm_stats {
 	u32 tx_cnt[T6_PM_NSTATS];
 	u32 rx_cnt[T6_PM_NSTATS];
@@ -64,6 +99,20 @@ struct cudbg_hw_sched {
 	u32 map;
 };
 
+struct cudbg_tcp_stats {
+	struct tp_tcp_stats v4, v6;
+};
+
+struct cudbg_tp_err_stats {
+	struct tp_err_stats stats;
+	u32 nchan;
+};
+
+struct cudbg_tp_fcoe_stats {
+	struct tp_fcoe_stats stats[4];
+	u32 nchan;
+};
+
 struct ireg_field {
 	u32 ireg_addr;
 	u32 ireg_data;
@@ -76,17 +125,80 @@ struct ireg_buf {
 	u32 outbuf[32];
 };
 
+struct cudbg_tp_cpl_stats {
+	struct tp_cpl_stats stats;
+	u32 nchan;
+};
+
+struct cudbg_wc_stats {
+	u32 wr_cl_success;
+	u32 wr_cl_fail;
+};
+
 struct cudbg_ulprx_la {
 	u32 data[ULPRX_LA_SIZE * 8];
 	u32 size;
 };
 
+struct cudbg_lb_stats {
+	int nchan;
+	struct lb_port_stats s[0];
+};
+
 struct cudbg_tp_la {
 	u32 size;
 	u32 mode;
 	u8 data[0];
 };
 
+static const char * const cudbg_region[] = {
+	"DBQ contexts:", "IMSG contexts:", "FLM cache:", "TCBs:",
+	"Pstructs:", "Timers:", "Rx FL:", "Tx FL:", "Pstruct FL:",
+	"Tx payload:", "Rx payload:", "LE hash:", "iSCSI region:",
+	"TDDP region:", "TPT region:", "STAG region:", "RQ region:",
+	"RQUDP region:", "PBL region:", "TXPBL region:",
+	"DBVFIFO region:", "ULPRX state:", "ULPTX state:",
+	"On-chip queues:"
+};
+
+/* Info relative to memory region (i.e. wrt 0). */
+struct cudbg_region_info {
+	bool exist; /* Does region exists in current memory region? */
+	u32 start;  /* Start wrt 0 */
+	u32 end;    /* End wrt 0 */
+};
+
+struct cudbg_port_usage {
+	u32 id;
+	u32 used;
+	u32 alloc;
+};
+
+struct cudbg_mem_desc {
+	u32 base;
+	u32 limit;
+	u32 idx;
+};
+
+struct cudbg_meminfo {
+	struct cudbg_mem_desc avail[4];
+	struct cudbg_mem_desc mem[ARRAY_SIZE(cudbg_region) + 3];
+	u32 avail_c;
+	u32 mem_c;
+	u32 up_ram_lo;
+	u32 up_ram_hi;
+	u32 up_extmem2_lo;
+	u32 up_extmem2_hi;
+	u32 rx_pages_data[3];
+	u32 tx_pages_data[4];
+	u32 p_structs;
+	struct cudbg_port_usage port_data[4];
+	u32 port_used[4];
+	u32 port_alloc[4];
+	u32 loopback_used[NCHAN];
+	u32 loopback_alloc[NCHAN];
+};
+
 struct cudbg_cim_pif_la {
 	int size;
 	u8 data[0];
@@ -108,6 +220,21 @@ struct cudbg_clk_info {
 	u32 dack_re;
 };
 
+#define CUDBG_MAC_STATS_REV 1
+
+struct cudbg_mac_stats_rev1 {
+	struct cudbg_ver_hdr ver_hdr;
+	u32 port_count;
+	u32 reserved;
+	struct port_stats stats[4];
+};
+
+struct cudbg_tx_rate {
+	u64 nrate[NCHAN];
+	u64 orate[NCHAN];
+	u32 nchan;
+};
+
 struct cudbg_tid_info_region {
 	u32 ntids;
 	u32 nstids;
@@ -145,6 +272,17 @@ struct cudbg_tid_info_region_rev1 {
 	u32 reserved[16];
 };
 
+#define CUDBG_MAX_INGRESS_QIDS 65536
+#define CUDBG_MAX_FL_QIDS 2048
+#define CUDBG_MAX_CNM_QIDS 1024
+#define CUDBG_LOWMEM_MAX_CTXT_QIDS 256
+
+struct cudbg_ch_cntxt {
+	uint32_t cntxt_type;
+	uint32_t cntxt_id;
+	uint32_t data[SGE_CTXT_SIZE / 4];
+};
+
 #define CUDBG_MAX_RPLC_SIZE 128
 
 struct cudbg_mps_tcam {
@@ -179,6 +317,38 @@ struct cudbg_vpd_data {
 	u32 vpd_vers;
 };
 
+enum cudbg_le_entry_types {
+	LE_ET_UNKNOWN = 0,
+	LE_ET_TCAM_CON,
+	LE_ET_TCAM_SERVER,
+	LE_ET_TCAM_FILTER,
+	LE_ET_TCAM_CLIP,
+	LE_ET_TCAM_ROUTING,
+	LE_ET_HASH_CON,
+	LE_ET_HASH_UNKNOWN,
+	LE_ET_INVALID_TID,
+};
+
+struct cudbg_tcam {
+	u32 filter_start;
+	u32 server_start;
+	u32 clip_start;
+	u32 routing_start;
+	u32 tid_hash_base;
+	u32 max_tid;
+};
+
+#define CUDBG_NUM_REQ_REGS 17
+#define CUDBG_MAX_TCAM_TID 0x800
+
+struct cudbg_tid_data {
+	u32 tid;
+	u32 dbig_cmd;
+	u32 dbig_conf;
+	u32 dbig_rsp_stat;
+	u32 data[CUDBG_NUM_REQ_REGS];
+};
+
 #define CUDBG_NUM_ULPTX 11
 #define CUDBG_NUM_ULPTX_READ 512
 
@@ -290,6 +460,23 @@ static const u32 t5_pm_tx_array[][IREG_NUM_ELEM] = {
 	{0x8FF0, 0x8FF4, 0x10021, 0x1D}, /* t5_pm_tx_regs_10021_to_1003c */
 };
 
+static const u32 t5_pcie_config_array[][2] = {
+	{0x0, 0x34},
+	{0x3c, 0x40},
+	{0x50, 0x64},
+	{0x70, 0x80},
+	{0x94, 0xa0},
+	{0xb0, 0xb8},
+	{0xd0, 0xd4},
+	{0x100, 0x128},
+	{0x140, 0x148},
+	{0x150, 0x164},
+	{0x170, 0x178},
+	{0x180, 0x194},
+	{0x1a0, 0x1b8},
+	{0x1c0, 0x208},
+};
+
 static const u32 t6_ma_ireg_array[][IREG_NUM_ELEM] = {
 	{0x78f8, 0x78fc, 0xa000, 23}, /* t6_ma_regs_a000_to_a016 */
 	{0x78f8, 0x78fc, 0xa400, 30}, /* t6_ma_regs_a400_to_a41e */
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cudbg_flash_utils.c b/drivers/net/ethernet/chelsio/cxgb4/cudbg_flash_utils.c
new file mode 100644
index 00000000..b29b948d
--- /dev/null
+++ b/drivers/net/ethernet/chelsio/cxgb4/cudbg_flash_utils.c
@@ -0,0 +1,241 @@
+/*
+ *  Copyright (C) 2017 Chelsio Communications.  All rights reserved.
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms and conditions of the GNU General Public License,
+ *  version 2, as published by the Free Software Foundation.
+ *
+ *  This program is distributed in the hope it will be useful, but WITHOUT
+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ *  more details.
+ *
+ *  The full GNU General Public License is included in this distribution in
+ *  the file called "COPYING".
+ *
+ */
+
+#include "cxgb4.h"
+#include "t4_hw.h"
+#include "cudbg_if.h"
+#include "cudbg_lib_common.h"
+
+static int write_flash(struct adapter *adap, u32 start_sec, void *data,
+		       u32 size)
+{
+	unsigned int sf_sec_size;
+	u8 *ptr = (u8 *)data;
+	unsigned int addr;
+	unsigned int i, n;
+	int rc = 0;
+
+	sf_sec_size = adap->params.sf_size / adap->params.sf_nsec;
+	addr =  start_sec * SF_SEC_SIZE;
+	i = DIV_ROUND_UP(size,/* # of sectors spanned */
+			 sf_sec_size);
+
+	rc = t4_flash_erase_sectors(adap, start_sec,
+				    start_sec + i - 1);
+	/* If size == 0 then we're simply erasing the FLASH sectors associated
+	 * with the on-adapter OptionROM Configuration File.
+	 */
+	if (rc || size == 0)
+		return rc;
+
+	/* this will write to the flash up to SF_PAGE_SIZE at a time */
+	for (i = 0; i < size; i += SF_PAGE_SIZE) {
+		if ((size - i) <  SF_PAGE_SIZE)
+			n = size - i;
+		else
+			n = SF_PAGE_SIZE;
+		rc = t4_write_flash(adap, addr, n, ptr, 0);
+		if (rc)
+			return rc;
+
+		addr += n;
+		ptr += n;
+	}
+
+	return 0;
+}
+
+static void set_sector_availability(struct cudbg_flash_sec_info *psec_info,
+				    int sector_nu, int avail)
+{
+	sector_nu -= FLASH_CUDBG_START_SEC;
+	if (avail)
+		set_dbg_bitmap(psec_info->sec_bitmap, sector_nu);
+	else
+		reset_dbg_bitmap(psec_info->sec_bitmap, sector_nu);
+}
+
+/* This function will return empty sector available for filling */
+static int find_empty_sec(struct cudbg_flash_sec_info *psec_info)
+{
+	int i, index, bit;
+
+	for (i = FLASH_CUDBG_START_SEC;
+	     i < FLASH_CUDBG_START_SEC + FLASH_CUDBG_NSECS;
+	     i++) {
+		index = (i - FLASH_CUDBG_START_SEC) / 8;
+		bit = (i - FLASH_CUDBG_START_SEC) % 8;
+		if (!(psec_info->sec_bitmap[index] & (1 << bit)))
+			return i;
+	}
+	return CUDBG_STATUS_FLASH_FULL;
+}
+
+/* This function will get header initially. If header is already there
+ * then it will update that header
+ */
+static void update_headers(struct cudbg_init *pdbg_init,
+			   struct cudbg_buffer *dbg_buff,
+			   u64 timestamp, u32 cur_entity_hdr_offset,
+			   u32 start_offset)
+{
+	struct cudbg_flash_sec_info *psec_info;
+	struct cudbg_entity_hdr *entity_hdr;
+	struct cudbg_flash_hdr *flash_hdr;
+	struct cudbg_hdr *cudbg_hdr;
+	u32 sec_hdr_start_addr;
+	u32 total_hdr_size;
+	u32 data_hdr_size;
+	u32 hdr_offset;
+	void *sec_hdr;
+
+	psec_info = pdbg_init->psec_info;
+	data_hdr_size = CUDBG_MAX_ENTITY * sizeof(struct cudbg_entity_hdr) +
+			sizeof(struct cudbg_hdr);
+	total_hdr_size = data_hdr_size + sizeof(struct cudbg_flash_hdr);
+	sec_hdr_start_addr = SF_SEC_SIZE - total_hdr_size;
+	sec_hdr = psec_info->sec_data + sec_hdr_start_addr;
+
+	flash_hdr = (struct cudbg_flash_hdr *)sec_hdr;
+	cudbg_hdr = (struct cudbg_hdr *)pdbg_init->outbuf;
+
+	/* initially initialize flash hdr and copy all data headers and
+	 * in next calling (else part) copy only current entity header
+	 */
+	if ((start_offset - psec_info->skip_size) == data_hdr_size) {
+		flash_hdr->signature = CUDBG_FL_SIGNATURE;
+		flash_hdr->major_ver = CUDBG_FL_MAJOR_VERSION;
+		flash_hdr->minor_ver = CUDBG_FL_MINOR_VERSION;
+		flash_hdr->build_ver = CUDBG_FL_BUILD_VERSION;
+		flash_hdr->hdr_len = sizeof(struct cudbg_flash_hdr);
+		hdr_offset =  sizeof(struct cudbg_flash_hdr);
+
+		memcpy((void *)((char *)sec_hdr + hdr_offset),
+		       (void *)((char *)dbg_buff->data), data_hdr_size);
+	} else {
+		memcpy((void *)((char *)sec_hdr +
+			sizeof(struct cudbg_flash_hdr) +
+			cur_entity_hdr_offset),
+			(void *)((char *)dbg_buff->data +
+			cur_entity_hdr_offset),
+			sizeof(struct cudbg_entity_hdr));
+	}
+
+	hdr_offset = data_hdr_size + sizeof(struct cudbg_flash_hdr);
+	flash_hdr->data_len = cudbg_hdr->data_len - psec_info->skip_size;
+	flash_hdr->timestamp = timestamp;
+
+	entity_hdr = (struct cudbg_entity_hdr *)((char *)sec_hdr +
+		      sizeof(struct cudbg_flash_hdr) +
+		      cur_entity_hdr_offset);
+	/* big entity like mc need to be skipped */
+	entity_hdr->start_offset -= psec_info->skip_size;
+
+	cudbg_hdr = (struct cudbg_hdr *)
+		    ((char *)sec_hdr + sizeof(struct cudbg_flash_hdr));
+	cudbg_hdr->data_len = flash_hdr->data_len;
+}
+
+/* Write CUDBG data into serial flash */
+int cudbg_write_flash(struct cudbg_init *pdbg_init,
+		      struct cudbg_buffer *dbg_buff,
+		      u32 start_offset, u32 cur_entity_hdr_offset,
+		      u32 cur_entity_size)
+{
+	struct cudbg_flash_hdr *flash_hdr = NULL;
+	struct cudbg_flash_sec_info *psec_info;
+	u64 timestamp = pdbg_init->time;
+	struct adapter *adap = NULL;
+	u32 sec_hdr_start_addr;
+	u32 sec_data_offset;
+	u32 total_hdr_size;
+	u32 sec_data_size;
+	u32 data_hdr_size;
+	u32 tmp_size;
+	u32 space_left;
+	int rc = 0;
+	int sec;
+
+	psec_info = pdbg_init->psec_info;
+	adap = pdbg_init->adap;
+
+	data_hdr_size = CUDBG_MAX_ENTITY * sizeof(struct cudbg_entity_hdr) +
+			sizeof(struct cudbg_hdr);
+	total_hdr_size = data_hdr_size + sizeof(struct cudbg_flash_hdr);
+	sec_hdr_start_addr = SF_SEC_SIZE - total_hdr_size;
+	sec_data_size = sec_hdr_start_addr;
+
+	dev_info(adap->pdev_dev, "\tWriting %u bytes to flash\n",
+		 cur_entity_size);
+
+	/* This function will get header if psec_info->sec_data does not
+	 * have any header and will update the header if it has header
+	 */
+
+	update_headers(pdbg_init, dbg_buff, timestamp,
+		       cur_entity_hdr_offset,
+		       start_offset);
+
+	flash_hdr = (struct cudbg_flash_hdr *)(psec_info->sec_data +
+					       sec_hdr_start_addr);
+
+	if (flash_hdr->data_len > FLASH_CUDBG_MAX_SIZE)
+		return CUDBG_STATUS_FLASH_FULL;
+
+	space_left = FLASH_CUDBG_MAX_SIZE - flash_hdr->data_len;
+	if (cur_entity_size > space_left)
+		return CUDBG_STATUS_FLASH_FULL;
+
+	while (cur_entity_size > 0) {
+		sec = find_empty_sec(psec_info);
+		if (psec_info->par_sec) {
+			sec_data_offset = psec_info->par_sec_offset;
+			set_sector_availability(psec_info, psec_info->par_sec, 0);
+			psec_info->par_sec = 0;
+			psec_info->par_sec_offset = 0;
+
+		} else {
+			psec_info->cur_seq_no++;
+			flash_hdr->sec_seq_no = psec_info->cur_seq_no;
+			sec_data_offset = 0;
+		}
+
+		if (cur_entity_size + sec_data_offset > sec_data_size) {
+			tmp_size = sec_data_size - sec_data_offset;
+		} else {
+			tmp_size = cur_entity_size;
+			psec_info->par_sec = sec;
+			psec_info->par_sec_offset = cur_entity_size +
+						    sec_data_offset;
+		}
+
+		memcpy((void *)((char *)psec_info->sec_data + sec_data_offset),
+		       (void *)((char *)dbg_buff->data + start_offset),
+		       tmp_size);
+
+		rc = write_flash(adap, sec, psec_info->sec_data,
+				 SF_SEC_SIZE);
+		if (rc)
+			return rc;
+
+		cur_entity_size -= tmp_size;
+		set_sector_availability(psec_info, sec, 1);
+		start_offset += tmp_size;
+	}
+
+	return rc;
+}
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cudbg_if.h b/drivers/net/ethernet/chelsio/cxgb4/cudbg_if.h
index e484c514..9e561d41 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cudbg_if.h
+++ b/drivers/net/ethernet/chelsio/cxgb4/cudbg_if.h
@@ -20,9 +20,11 @@
 
 /* Error codes */
 #define CUDBG_STATUS_NO_MEM -19
+#define CUDBG_STATUS_OUTBUFF_OVERFLOW -20
 #define CUDBG_STATUS_ENTITY_NOT_FOUND -24
 #define CUDBG_SYSTEM_ERROR -29
 #define CUDBG_STATUS_CCLK_NOT_DEFINED -32
+#define CUDBG_STATUS_FLASH_FULL -33
 
 #define CUDBG_MAJOR_VERSION 1
 #define CUDBG_MINOR_VERSION 14
@@ -47,42 +49,106 @@ enum cudbg_dbg_entity_type {
 	CUDBG_CIM_OBQ_NCSI = 17,
 	CUDBG_EDC0 = 18,
 	CUDBG_EDC1 = 19,
+	CUDBG_MC0 = 20,
+	CUDBG_MC1 = 21,
 	CUDBG_RSS = 22,
+	CUDBG_RSS_PF_CONF = 23,
+	CUDBG_RSS_KEY = 24,
 	CUDBG_RSS_VF_CONF = 25,
+	CUDBG_RSS_CONF = 26,
 	CUDBG_PATH_MTU = 27,
+	CUDBG_SW_STATE = 28,
+	/* WTP */
 	CUDBG_PM_STATS = 30,
 	CUDBG_HW_SCHED = 31,
+	CUDBG_TCP_STATS = 32,
+	CUDBG_TP_ERR_STATS = 33,
+	CUDBG_FCOE_STATS = 34,
+	CUDBG_RDMA_STATS = 35,
 	CUDBG_TP_INDIRECT = 36,
 	CUDBG_SGE_INDIRECT = 37,
+	CUDBG_CPL_STATS = 38,
+	CUDBG_DDP_STATS = 39,
+	CUDBG_WC_STATS = 40,
 	CUDBG_ULPRX_LA = 41,
+	CUDBG_LB_STATS = 42,
 	CUDBG_TP_LA = 43,
+	CUDBG_MEMINFO = 44,
 	CUDBG_CIM_PIF_LA = 45,
 	CUDBG_CLK = 46,
 	CUDBG_CIM_OBQ_RXQ0 = 47,
 	CUDBG_CIM_OBQ_RXQ1 = 48,
+	CUDBG_MAC_STATS = 49,
 	CUDBG_PCIE_INDIRECT = 50,
 	CUDBG_PM_INDIRECT = 51,
+	CUDBG_FULL = 52,
+	CUDBG_TX_RATE = 53,
 	CUDBG_TID_INFO = 54,
+	CUDBG_PCIE_CONFIG = 55,
+	CUDBG_DUMP_CONTEXT = 56,
 	CUDBG_MPS_TCAM = 57,
 	CUDBG_VPD_DATA = 58,
+	CUDBG_LE_TCAM = 59,
 	CUDBG_CCTRL = 60,
 	CUDBG_MA_INDIRECT = 61,
 	CUDBG_ULPTX_LA = 62,
+	/* EXT */
 	CUDBG_UP_CIM_INDIRECT = 64,
 	CUDBG_PBT_TABLE = 65,
 	CUDBG_MBOX_LOG = 66,
 	CUDBG_HMA_INDIRECT = 67,
+	CUDBG_HMA = 68,
+	CUDBG_UPLOAD = 69,
 	CUDBG_MAX_ENTITY = 70,
 };
 
+struct cudbg_flash_sec_info {
+	int par_sec;		   /* Represent partially filled sector no */
+	int par_sec_offset;	   /* Offset in partially filled sector */
+	int cur_seq_no;
+	u32 max_seq_no;
+	u32 max_seq_sec;
+	u32 hdr_data_len;	   /* Total data */
+	u32 skip_size;		   /* Total size of large entities. */
+	u64 max_timestamp;
+	char sec_data[SF_SEC_SIZE];
+	u8 sec_bitmap[8];
+};
+
 struct cudbg_init {
 	struct adapter *adap; /* Pointer to adapter structure */
 	void *outbuf; /* Output buffer */
 	u32 outbuf_size;  /* Output buffer size */
+	u8 compress_type; /* Type of compression to use */
+	bool use_flash; /* If set, debug entity is also written to flash */
+	u64 time; /* Timestamp */
+	unsigned char *hash_table; /* Hash table used for fastlz compression */
+	void *compress_buff; /* Buffer used for compression */
+	struct cudbg_flash_sec_info *psec_info; /* Flash sector information */
+};
+
+enum {
+	CUDBG_OS_TYPE_LINUX = 2,
 };
 
 static inline unsigned int cudbg_mbytes_to_bytes(unsigned int size)
 {
 	return size * 1024 * 1024;
 }
+
+static inline void set_dbg_bitmap(u8 *bitmap, enum cudbg_dbg_entity_type type)
+{
+	int index = type / 8;
+	int bit = type % 8;
+
+	bitmap[index] |= (1 << bit);
+}
+
+static inline void reset_dbg_bitmap(u8 *bitmap, enum cudbg_dbg_entity_type type)
+{
+	int index = type / 8;
+	int bit = type % 8;
+
+	bitmap[index] &= ~(1 << bit);
+}
 #endif /* __CUDBG_IF_H__ */
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cudbg_lib.c b/drivers/net/ethernet/chelsio/cxgb4/cudbg_lib.c
index fe3a9ef0..8b4e0ff9 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cudbg_lib.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cudbg_lib.c
@@ -15,18 +15,67 @@
  *
  */
 
+#include <linux/sort.h>
+
 #include "t4_regs.h"
 #include "cxgb4.h"
 #include "cudbg_if.h"
 #include "cudbg_lib_common.h"
 #include "cudbg_lib.h"
 #include "cudbg_entity.h"
+#include "fastlz_common.h"
 
-static void cudbg_write_and_release_buff(struct cudbg_buffer *pin_buff,
-					 struct cudbg_buffer *dbg_buff)
+static int cudbg_do_compression(struct cudbg_init *pdbg_init,
+				struct cudbg_buffer *pin_buff,
+				struct cudbg_buffer *dbg_buff)
 {
-	cudbg_update_buff(pin_buff, dbg_buff);
+	struct cudbg_buffer temp_in_buff = { 0 };
+	int bytes_left, bytes_read, bytes;
+	u32 offset = dbg_buff->offset;
+	int rc;
+
+	temp_in_buff.offset = pin_buff->offset;
+	temp_in_buff.data = pin_buff->data;
+	temp_in_buff.size = pin_buff->size;
+
+	bytes_left = pin_buff->size;
+	bytes_read = 0;
+	while (bytes_left > 0) {
+		bytes = min_t(unsigned long, bytes_left,
+			      (unsigned long)CUDBG_CHUNK_SIZE);
+		temp_in_buff.data = (char *)pin_buff->data + bytes_read;
+		temp_in_buff.size = bytes;
+		rc = cudbg_compress_buff(pdbg_init, &temp_in_buff, dbg_buff);
+		if (rc)
+			return rc;
+		bytes_left -= bytes;
+		bytes_read += bytes;
+	}
+
+	pin_buff->size = dbg_buff->offset - offset;
+	return 0;
+}
+
+static int cudbg_write_and_release_buff(struct cudbg_init *pdbg_init,
+					struct cudbg_buffer *pin_buff,
+					struct cudbg_buffer *dbg_buff)
+{
+	int rc = 0;
+
+	if (pdbg_init->compress_type == CUDBG_COMPRESSION_NONE) {
+		cudbg_update_buff(pin_buff, dbg_buff);
+	} else {
+		rc = cudbg_write_compression_hdr(pdbg_init, pin_buff, dbg_buff);
+		if (rc)
+			goto out;
+
+		rc = cudbg_do_compression(pdbg_init, pin_buff, dbg_buff);
+		if (rc)
+			goto out;
+	}
+out:
 	cudbg_put_buff(pin_buff, dbg_buff);
+	return rc;
 }
 
 static int is_fw_attached(struct cudbg_init *pdbg_init)
@@ -68,6 +117,468 @@ struct cudbg_entity_hdr *cudbg_get_entity_hdr(void *outbuf, int i)
 		(sizeof(struct cudbg_entity_hdr) * (i - 1)));
 }
 
+int cudbg_wr_entity_to_flash(struct cudbg_init *pdbg_init,
+			     struct cudbg_buffer *dbg_buff,
+			     struct cudbg_entity_hdr *entity_hdr)
+{
+	u32 cur_entity_hdr_offset = sizeof(struct cudbg_hdr);
+	u32 cur_entity_data_offset, cur_entity_size;
+	u32 remain_flash_size, flash_data_offset;
+	struct adapter *padap = pdbg_init->adap;
+	u32 data_hdr_size;
+	int rc = -1;
+
+	cur_entity_data_offset = entity_hdr->start_offset;
+	cur_entity_size = entity_hdr->size;
+
+	data_hdr_size = CUDBG_MAX_ENTITY * sizeof(struct cudbg_entity_hdr) +
+			sizeof(struct cudbg_hdr);
+	flash_data_offset = (FLASH_CUDBG_NSECS *
+			     (sizeof(struct cudbg_flash_hdr) + data_hdr_size)) +
+			    cur_entity_data_offset - data_hdr_size;
+
+	if (flash_data_offset > FLASH_CUDBG_MAX_SIZE)
+		return -ENOMEM;
+
+	remain_flash_size = FLASH_CUDBG_MAX_SIZE - flash_data_offset;
+	if (cur_entity_size > remain_flash_size) {
+		dev_warn(padap->pdev_dev, "Large entity. Skipping");
+	} else {
+		cur_entity_hdr_offset += sizeof(struct cudbg_entity_hdr) *
+					 (entity_hdr->entity_type - 1);
+		rc = cudbg_write_flash(pdbg_init, dbg_buff, cur_entity_data_offset,
+				       cur_entity_hdr_offset, cur_entity_size);
+		if (rc == CUDBG_STATUS_FLASH_FULL)
+			dev_err(padap->pdev_dev, "\n\tFLASH is full... ");
+	}
+
+	return rc;
+}
+
+static int cudbg_eeprom_ptov(u32 phys_addr, u32 fn, u32 sz)
+{
+	fn *= sz;
+	if (phys_addr < 1024)
+		return phys_addr + (31 << 10);
+	if (phys_addr < 1024 + fn)
+		return 31744 - fn + phys_addr - 1024;
+	if (phys_addr < EEPROMSIZE)
+		return phys_addr - 1024 - fn;
+	return -EINVAL;
+}
+
+static int cudbg_get_port_count(struct cudbg_init *pdbg_init)
+{
+	u8 port_type[CUDBG_PORT_TYPE_LEN + 1] = { 0 };
+	struct adapter *padap = pdbg_init->adap;
+	u32 v, port_vec, port_count;
+	unsigned int i;
+	char *tmp;
+	int rc;
+
+	v = FW_PARAMS_MNEM_V(FW_PARAMS_MNEM_DEV) |
+	    FW_PARAMS_PARAM_X_V(FW_PARAMS_PARAM_DEV_PORTVEC);
+	port_count = 0;
+	if (is_fw_attached(pdbg_init)) {
+		rc = t4_query_params(padap, padap->mbox, padap->pf, 0, 1,
+				     &v, &port_vec);
+		if (rc >= 0)
+			port_count = hweight32(port_vec);
+	}
+
+	if (!port_count) {
+		u32 vaddr;
+
+		vaddr = cudbg_eeprom_ptov(CUDBG_PORT_TYPE_ADDR, padap->pf,
+					  EEPROMPFSIZE);
+		if (vaddr < 0)
+			return vaddr;
+
+		rc = pci_read_vpd(padap->pdev, vaddr, CUDBG_PORT_TYPE_LEN,
+				  port_type);
+		if (rc < 0)
+			return rc;
+
+		/* port_vec will be like 0x0e0effff
+		 * ff means not active
+		 * rather than ff meaning active port
+		 */
+		tmp = (char *)port_type;
+		for (i = 0; i < CUDBG_PORT_TYPE_LEN; i += 2) {
+			if (!strncmp(&tmp[i], "FF", 2))
+				continue;
+			port_count++;
+		}
+	}
+	return port_count;
+}
+
+static int cudbg_mem_desc_cmp(const void *a, const void *b)
+{
+	return ((const struct cudbg_mem_desc *)a)->base -
+	       ((const struct cudbg_mem_desc *)b)->base;
+}
+
+static int cudbg_fill_meminfo(struct adapter *padap,
+			      struct cudbg_meminfo *meminfo_buff)
+{
+	struct cudbg_mem_desc *md;
+	u32 size, lo, hi;
+	int n, i, rc = 0;
+	u32 used, alloc;
+
+	size = sizeof(struct cudbg_meminfo);
+
+	memset(meminfo_buff->avail, 0,
+	       ARRAY_SIZE(meminfo_buff->avail) *
+	       sizeof(struct cudbg_mem_desc));
+	memset(meminfo_buff->mem, 0,
+	       (ARRAY_SIZE(cudbg_region) + 3) * sizeof(struct cudbg_mem_desc));
+	md  = meminfo_buff->mem;
+
+	for (i = 0; i < ARRAY_SIZE(meminfo_buff->mem); i++) {
+		meminfo_buff->mem[i].limit = 0;
+		meminfo_buff->mem[i].idx = i;
+	}
+
+	i = 0;
+	lo = t4_read_reg(padap, MA_TARGET_MEM_ENABLE_A);
+	if (lo & EDRAM0_ENABLE_F) {
+		hi = t4_read_reg(padap, MA_EDRAM0_BAR_A);
+		meminfo_buff->avail[i].base = EDRAM0_BASE_G(hi) << 20;
+		meminfo_buff->avail[i].limit = meminfo_buff->avail[i].base +
+					       (EDRAM0_SIZE_G(hi) << 20);
+		meminfo_buff->avail[i].idx = 0;
+		i++;
+	}
+
+	if (lo & EDRAM1_ENABLE_F) {
+		hi =  t4_read_reg(padap, MA_EDRAM1_BAR_A);
+		meminfo_buff->avail[i].base = EDRAM1_BASE_G(hi) << 20;
+		meminfo_buff->avail[i].limit = meminfo_buff->avail[i].base +
+					       (EDRAM1_SIZE_G(hi) << 20);
+		meminfo_buff->avail[i].idx = 1;
+		i++;
+	}
+
+	if (is_t5(padap->params.chip)) {
+		if (lo & EXT_MEM0_ENABLE_F) {
+			hi = t4_read_reg(padap, MA_EXT_MEMORY0_BAR_A);
+			meminfo_buff->avail[i].base = EXT_MEM_BASE_G(hi) << 20;
+			meminfo_buff->avail[i].limit =
+				meminfo_buff->avail[i].base +
+				(EXT_MEM_SIZE_G(hi) << 20);
+			meminfo_buff->avail[i].idx = 3;
+			i++;
+		}
+
+		if (lo & EXT_MEM1_ENABLE_F) {
+			hi = t4_read_reg(padap, MA_EXT_MEMORY1_BAR_A);
+			meminfo_buff->avail[i].base = EXT_MEM1_BASE_G(hi) << 20;
+			meminfo_buff->avail[i].limit =
+				meminfo_buff->avail[i].base +
+				(EXT_MEM1_SIZE_G(hi) << 20);
+			meminfo_buff->avail[i].idx = 4;
+			i++;
+		}
+	} else if (is_t6(padap->params.chip)) {
+		if (lo & EXT_MEM_ENABLE_F) {
+			hi = t4_read_reg(padap, MA_EXT_MEMORY_BAR_A);
+			meminfo_buff->avail[i].base = EXT_MEM_BASE_G(hi) << 20;
+			meminfo_buff->avail[i].limit =
+				meminfo_buff->avail[i].base +
+				(EXT_MEM_SIZE_G(hi) << 20);
+			meminfo_buff->avail[i].idx = 2;
+			i++;
+		}
+
+		if (lo & HMA_MUX_F) {
+			hi = t4_read_reg(padap, MA_EXT_MEMORY1_BAR_A);
+			meminfo_buff->avail[i].base = EXT_MEM1_BASE_G(hi) << 20;
+			meminfo_buff->avail[i].limit =
+				meminfo_buff->avail[i].base +
+				(EXT_MEM1_SIZE_G(hi) << 20);
+			meminfo_buff->avail[i].idx = 5;
+			i++;
+		}
+	}
+
+	if (!i) {				   /* no memory available */
+		rc = CUDBG_STATUS_ENTITY_NOT_FOUND;
+		goto err;
+	}
+
+	meminfo_buff->avail_c = i;
+	sort(meminfo_buff->avail, i, sizeof(struct cudbg_mem_desc),
+	     cudbg_mem_desc_cmp, NULL);
+	(md++)->base = t4_read_reg(padap, SGE_DBQ_CTXT_BADDR_A);
+	(md++)->base = t4_read_reg(padap, SGE_IMSG_CTXT_BADDR_A);
+	(md++)->base = t4_read_reg(padap, SGE_FLM_CACHE_BADDR_A);
+	(md++)->base = t4_read_reg(padap, TP_CMM_TCB_BASE_A);
+	(md++)->base = t4_read_reg(padap, TP_CMM_MM_BASE_A);
+	(md++)->base = t4_read_reg(padap, TP_CMM_TIMER_BASE_A);
+	(md++)->base = t4_read_reg(padap, TP_CMM_MM_RX_FLST_BASE_A);
+	(md++)->base = t4_read_reg(padap, TP_CMM_MM_TX_FLST_BASE_A);
+	(md++)->base = t4_read_reg(padap, TP_CMM_MM_PS_FLST_BASE_A);
+
+	/* the next few have explicit upper bounds */
+	md->base = t4_read_reg(padap, TP_PMM_TX_BASE_A);
+	md->limit = md->base - 1 +
+		    t4_read_reg(padap,
+				TP_PMM_TX_PAGE_SIZE_A) *
+				PMTXMAXPAGE_G(t4_read_reg(padap,
+							  TP_PMM_TX_MAX_PAGE_A)
+					     );
+	md++;
+
+	md->base = t4_read_reg(padap, TP_PMM_RX_BASE_A);
+	md->limit = md->base - 1 +
+		    t4_read_reg(padap,
+				TP_PMM_RX_PAGE_SIZE_A) *
+				PMRXMAXPAGE_G(t4_read_reg(padap,
+							  TP_PMM_RX_MAX_PAGE_A)
+					      );
+	md++;
+	if (t4_read_reg(padap, LE_DB_CONFIG_A) & HASHEN_F) {
+		if (CHELSIO_CHIP_VERSION(padap->params.chip) <= CHELSIO_T5) {
+			hi = t4_read_reg(padap, LE_DB_TID_HASHBASE_A) / 4;
+			md->base = t4_read_reg(padap, LE_DB_HASH_TID_BASE_A);
+		} else {
+			hi = t4_read_reg(padap, LE_DB_HASH_TID_BASE_A);
+			md->base = t4_read_reg(padap,
+					       LE_DB_HASH_TBL_BASE_ADDR_A);
+		}
+		md->limit = 0;
+	} else {
+		md->base = 0;
+		md->idx = ARRAY_SIZE(cudbg_region);  /* hide it */
+	}
+	md++;
+#define ulp_region(reg) \
+	{\
+		md->base = t4_read_reg(padap, ULP_ ## reg ## _LLIMIT_A);\
+		(md++)->limit = t4_read_reg(padap, ULP_ ## reg ## _ULIMIT_A);\
+	}
+
+	ulp_region(RX_ISCSI);
+	ulp_region(RX_TDDP);
+	ulp_region(TX_TPT);
+	ulp_region(RX_STAG);
+	ulp_region(RX_RQ);
+	ulp_region(RX_RQUDP);
+	ulp_region(RX_PBL);
+	ulp_region(TX_PBL);
+#undef ulp_region
+	md->base = 0;
+	md->idx = ARRAY_SIZE(cudbg_region);
+	if (!is_t4(padap->params.chip)) {
+		u32 sge_ctrl = t4_read_reg(padap, SGE_CONTROL2_A);
+		u32 fifo_size = t4_read_reg(padap, SGE_DBVFIFO_SIZE_A);
+
+		if (is_t5(padap->params.chip)) {
+			if (sge_ctrl & VFIFO_ENABLE_F)
+				size = DBVFIFO_SIZE_G(fifo_size);
+		} else
+			size = T6_DBVFIFO_SIZE_G(fifo_size);
+
+		if (size) {
+			md->base = BASEADDR_G(t4_read_reg(padap,
+							  SGE_DBVFIFO_BADDR_A));
+			md->limit = md->base + (size << 2) - 1;
+		}
+	}
+
+	md++;
+
+	md->base = t4_read_reg(padap, ULP_RX_CTX_BASE_A);
+	md->limit = 0;
+	md++;
+	md->base = t4_read_reg(padap, ULP_TX_ERR_TABLE_BASE_A);
+	md->limit = 0;
+	md++;
+
+	md->base = padap->vres.ocq.start;
+	if (padap->vres.ocq.size)
+		md->limit = md->base + padap->vres.ocq.size - 1;
+	else
+		md->idx = ARRAY_SIZE(cudbg_region);  /* hide it */
+	md++;
+
+	/* add any address-space holes, there can be up to 3 */
+	for (n = 0; n < i - 1; n++)
+		if (meminfo_buff->avail[n].limit <
+		    meminfo_buff->avail[n + 1].base)
+			(md++)->base = meminfo_buff->avail[n].limit;
+
+	if (meminfo_buff->avail[n].limit)
+		(md++)->base = meminfo_buff->avail[n].limit;
+
+	n = (int) (md - meminfo_buff->mem);
+	meminfo_buff->mem_c = n;
+
+	sort(meminfo_buff->mem, n, sizeof(struct cudbg_mem_desc),
+	     cudbg_mem_desc_cmp, NULL);
+
+	lo = t4_read_reg(padap, CIM_SDRAM_BASE_ADDR_A);
+	hi = t4_read_reg(padap, CIM_SDRAM_ADDR_SIZE_A) + lo - 1;
+	meminfo_buff->up_ram_lo = lo;
+	meminfo_buff->up_ram_hi = hi;
+
+	lo = t4_read_reg(padap, CIM_EXTMEM2_BASE_ADDR_A);
+	hi = t4_read_reg(padap, CIM_EXTMEM2_ADDR_SIZE_A) + lo - 1;
+	meminfo_buff->up_extmem2_lo = lo;
+	meminfo_buff->up_extmem2_hi = hi;
+
+	lo = t4_read_reg(padap, TP_PMM_RX_MAX_PAGE_A);
+	meminfo_buff->rx_pages_data[0] =  PMRXMAXPAGE_G(lo);
+	meminfo_buff->rx_pages_data[1] =
+		t4_read_reg(padap, TP_PMM_RX_PAGE_SIZE_A) >> 10;
+	meminfo_buff->rx_pages_data[2] = (lo & PMRXNUMCHN_F) ? 2 : 1 ;
+
+	lo = t4_read_reg(padap, TP_PMM_TX_MAX_PAGE_A);
+	hi = t4_read_reg(padap, TP_PMM_TX_PAGE_SIZE_A);
+	meminfo_buff->tx_pages_data[0] = PMTXMAXPAGE_G(lo);
+	meminfo_buff->tx_pages_data[1] =
+		hi >= (1 << 20) ? (hi >> 20) : (hi >> 10);
+	meminfo_buff->tx_pages_data[2] =
+		hi >= (1 << 20) ? 'M' : 'K';
+	meminfo_buff->tx_pages_data[3] = 1 << PMTXNUMCHN_G(lo);
+
+	for (i = 0; i < 4; i++) {
+		if (CHELSIO_CHIP_VERSION(padap->params.chip) > CHELSIO_T5)
+			lo = t4_read_reg(padap,
+					 MPS_RX_MAC_BG_PG_CNT0_A + i * 4);
+		else
+			lo = t4_read_reg(padap, MPS_RX_PG_RSV0_A + i * 4);
+		if (is_t5(padap->params.chip)) {
+			used = T5_USED_G(lo);
+			alloc = T5_ALLOC_G(lo);
+		} else {
+			used = USED_G(lo);
+			alloc = ALLOC_G(lo);
+		}
+		meminfo_buff->port_used[i] = used;
+		meminfo_buff->port_alloc[i] = alloc;
+	}
+
+	for (i = 0; i < padap->params.arch.nchan; i++) {
+		if (CHELSIO_CHIP_VERSION(padap->params.chip) > CHELSIO_T5)
+			lo = t4_read_reg(padap,
+					 MPS_RX_LPBK_BG_PG_CNT0_A + i * 4);
+		else
+			lo = t4_read_reg(padap, MPS_RX_PG_RSV4_A + i * 4);
+		if (is_t5(padap->params.chip)) {
+			used = T5_USED_G(lo);
+			alloc = T5_ALLOC_G(lo);
+		} else {
+			used = USED_G(lo);
+			alloc = ALLOC_G(lo);
+		}
+		meminfo_buff->loopback_used[i] = used;
+		meminfo_buff->loopback_alloc[i] = alloc;
+	}
+err:
+	return rc;
+}
+
+/**
+ * Fetch the TX/RX payload regions start and end.
+ *
+ * @padap (IN): adapter handle.
+ * @mem_type (IN): EDC0, EDC1, MC/MC0/MC1.
+ * @mem_tot_len (IN): total length of @mem_type memory region to read.
+ * @payload_type (IN): TX or RX Payload.
+ * @reg_info (OUT): store the payload region info.
+ *
+ * Fetch the TX/RX payload region information from meminfo.
+ * However, reading from the @mem_type region starts at 0 and not
+ * from whatever base info is stored in meminfo.  Hence, if the
+ * payload region exists, then calculate the payload region
+ * start and end wrt 0 and @mem_tot_len, respectively, and set
+ * @reg_info->exist to true. Otherwise, set @reg_info->exist to false.
+ */
+static int cudbg_get_payload_range(struct adapter *padap, u8 mem_type,
+				   unsigned long mem_tot_len, u8 payload_type,
+				   struct cudbg_region_info *reg_info)
+{
+	struct cudbg_mem_desc mem_region;
+	struct cudbg_mem_desc payload;
+	struct cudbg_meminfo meminfo;
+	u32 i, idx, found = 0;
+	u8 mc_type;
+	int rc;
+
+	/* Get meminfo of all regions */
+	rc = cudbg_fill_meminfo(padap, &meminfo);
+	if (rc)
+		return rc;
+
+	/* Extract the specified TX or RX Payload region range */
+	memset(&payload, 0, sizeof(struct cudbg_mem_desc));
+	for (i = 0; i < meminfo.mem_c; i++) {
+		if (meminfo.mem[i].idx >= ARRAY_SIZE(cudbg_region))
+			continue;                        /* skip holes */
+
+		idx = meminfo.mem[i].idx;
+		/* Get TX or RX Payload region start and end */
+		if (idx == payload_type) {
+			if (!(meminfo.mem[i].limit))
+				meminfo.mem[i].limit =
+					i < meminfo.mem_c - 1 ?
+					meminfo.mem[i + 1].base - 1 : ~0;
+
+			memcpy(&payload, &meminfo.mem[i], sizeof(payload));
+			found = 1;
+			break;
+		}
+	}
+
+	/* If TX or RX Payload region is not found return error. */
+	if (!found)
+		return -EINVAL;
+
+	if (mem_type < MEM_MC) {
+		memcpy(&mem_region, &meminfo.avail[mem_type],
+		       sizeof(mem_region));
+	} else {
+		/* Check if both MC0 and MC1 exist by checking if a
+		 * base address for the specified @mem_type exists.
+		 * If a base address exists, then there is MC1 and
+		 * hence use the base address stored at index 3.
+		 * Otherwise, use the base address stored at index 2.
+		 */
+		mc_type = meminfo.avail[mem_type].base ?
+			  mem_type : mem_type - 1;
+		memcpy(&mem_region, &meminfo.avail[mc_type],
+		       sizeof(mem_region));
+	}
+
+	/* Check if payload region exists in current memory */
+	if (payload.base < mem_region.base && payload.limit < mem_region.base) {
+		reg_info->exist = false;
+		return 0;
+	}
+
+	/* Get Payload region start and end with respect to 0 and
+	 * mem_tot_len, respectively.  This is because reading from the
+	 * memory region starts at 0 and not at base info stored in meminfo.
+	 */
+	if (payload.base < mem_region.limit) {
+		reg_info->exist = true;
+		if (payload.base >= mem_region.base)
+			reg_info->start = payload.base - mem_region.base;
+		else
+			reg_info->start = 0;
+
+		if (payload.limit < mem_region.limit)
+			reg_info->end = payload.limit - mem_region.base;
+		else
+			reg_info->end = mem_tot_len;
+	}
+
+	return 0;
+}
+
 int cudbg_collect_reg_dump(struct cudbg_init *pdbg_init,
 			   struct cudbg_buffer *dbg_buff,
 			   struct cudbg_error *cudbg_err)
@@ -82,12 +593,11 @@ int cudbg_collect_reg_dump(struct cudbg_init *pdbg_init,
 	else if (is_t5(padap->params.chip) || is_t6(padap->params.chip))
 		buf_size = T5_REGMAP_SIZE;
 
-	rc = cudbg_get_buff(dbg_buff, buf_size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, buf_size, &temp_buff);
 	if (rc)
 		return rc;
 	t4_get_regs(padap, (void *)temp_buff.data, temp_buff.size);
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_fw_devlog(struct cudbg_init *pdbg_init,
@@ -106,7 +616,7 @@ int cudbg_collect_fw_devlog(struct cudbg_init *pdbg_init,
 	}
 
 	dparams = &padap->params.devlog;
-	rc = cudbg_get_buff(dbg_buff, dparams->size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, dparams->size, &temp_buff);
 	if (rc)
 		return rc;
 
@@ -120,13 +630,12 @@ int cudbg_collect_fw_devlog(struct cudbg_init *pdbg_init,
 				  1);
 		spin_unlock(&padap->win0_lock);
 		if (rc) {
-			cudbg_err->sys_err = rc;
+			cudbg_err->sys_err = CUDBG_SYSTEM_ERROR;
 			cudbg_put_buff(&temp_buff, dbg_buff);
 			return rc;
 		}
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_cim_la(struct cudbg_init *pdbg_init,
@@ -147,7 +656,7 @@ int cudbg_collect_cim_la(struct cudbg_init *pdbg_init,
 	}
 
 	size += sizeof(cfg);
-	rc = cudbg_get_buff(dbg_buff, size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
 	if (rc)
 		return rc;
 
@@ -167,8 +676,7 @@ int cudbg_collect_cim_la(struct cudbg_init *pdbg_init,
 		cudbg_put_buff(&temp_buff, dbg_buff);
 		return rc;
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_cim_ma_la(struct cudbg_init *pdbg_init,
@@ -180,7 +688,7 @@ int cudbg_collect_cim_ma_la(struct cudbg_init *pdbg_init,
 	int size, rc;
 
 	size = 2 * CIM_MALA_SIZE * 5 * sizeof(u32);
-	rc = cudbg_get_buff(dbg_buff, size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
 	if (rc)
 		return rc;
 
@@ -188,8 +696,7 @@ int cudbg_collect_cim_ma_la(struct cudbg_init *pdbg_init,
 			  (u32 *)temp_buff.data,
 			  (u32 *)((char *)temp_buff.data +
 				  5 * CIM_MALA_SIZE));
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_cim_qcfg(struct cudbg_init *pdbg_init,
@@ -201,7 +708,7 @@ int cudbg_collect_cim_qcfg(struct cudbg_init *pdbg_init,
 	struct cudbg_cim_qcfg *cim_qcfg_data;
 	int rc;
 
-	rc = cudbg_get_buff(dbg_buff, sizeof(struct cudbg_cim_qcfg),
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_cim_qcfg),
 			    &temp_buff);
 	if (rc)
 		return rc;
@@ -227,8 +734,7 @@ int cudbg_collect_cim_qcfg(struct cudbg_init *pdbg_init,
 
 	t4_read_cimq_cfg(padap, cim_qcfg_data->base, cim_qcfg_data->size,
 			 cim_qcfg_data->thres);
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 static int cudbg_read_cim_ibq(struct cudbg_init *pdbg_init,
@@ -242,7 +748,7 @@ static int cudbg_read_cim_ibq(struct cudbg_init *pdbg_init,
 
 	/* collect CIM IBQ */
 	qsize = CIM_IBQ_SIZE * 4 * sizeof(u32);
-	rc = cudbg_get_buff(dbg_buff, qsize, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, qsize, &temp_buff);
 	if (rc)
 		return rc;
 
@@ -259,8 +765,7 @@ static int cudbg_read_cim_ibq(struct cudbg_init *pdbg_init,
 		cudbg_put_buff(&temp_buff, dbg_buff);
 		return rc;
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_cim_ibq_tp0(struct cudbg_init *pdbg_init,
@@ -327,7 +832,7 @@ static int cudbg_read_cim_obq(struct cudbg_init *pdbg_init,
 
 	/* collect CIM OBQ */
 	qsize =  cudbg_cim_obq_size(padap, qid);
-	rc = cudbg_get_buff(dbg_buff, qsize, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, qsize, &temp_buff);
 	if (rc)
 		return rc;
 
@@ -344,8 +849,7 @@ static int cudbg_read_cim_obq(struct cudbg_init *pdbg_init,
 		cudbg_put_buff(&temp_buff, dbg_buff);
 		return rc;
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_cim_obq_ulp0(struct cudbg_init *pdbg_init,
@@ -409,18 +913,98 @@ static int cudbg_read_fw_mem(struct cudbg_init *pdbg_init,
 			     unsigned long tot_len,
 			     struct cudbg_error *cudbg_err)
 {
+	struct cudbg_region_info payload[2]; /* TX and RX Payload Region */
 	unsigned long bytes, bytes_left, bytes_read = 0;
 	struct adapter *padap = pdbg_init->adap;
 	struct cudbg_buffer temp_buff = { 0 };
+	u8 i, region_index[2], j = 0;
+	u32 yield_count = 0;
 	int rc = 0;
 
+	/* Zero out the payload data */
+	/* Find the index of TX and RX Payload regions in meminfo */
+	for (i = 0; i < ARRAY_SIZE(cudbg_region); i++) {
+		if (!strcmp(cudbg_region[i], "Tx payload:") ||
+		    !strcmp(cudbg_region[i], "Rx payload:")) {
+			region_index[j] = i;
+			j++;
+			if (j == 2)
+				break;
+		}
+	}
+
+	/* Get TX/RX Payload region range if they exist */
+	memset(payload, 0, ARRAY_SIZE(payload) * sizeof(payload[0]));
+	for (i = 0; i < ARRAY_SIZE(payload); i++) {
+		rc = cudbg_get_payload_range(padap, mem_type, tot_len,
+					     region_index[i],
+					     &payload[i]);
+		if (rc)
+			return rc;
+
+		if (payload[i].exist) {
+			/* Align start and end to avoid wrap around */
+			payload[i].start =
+				roundup(payload[i].start,
+					CUDBG_CHUNK_SIZE);
+			payload[i].end =
+				rounddown(payload[i].end,
+					  CUDBG_CHUNK_SIZE);
+		}
+	}
+
+	if (pdbg_init->compress_type != CUDBG_COMPRESSION_NONE) {
+		/* Request a small chunk enough to write compression header */
+		rc = cudbg_get_buff(pdbg_init, dbg_buff, CUDBG_CHUNK_SIZE,
+				    &temp_buff);
+		if (rc)
+			return rc;
+
+		/* Update with actual length of the entity to be written
+		 * into compression header.
+		 */
+		temp_buff.size = tot_len;
+		rc = cudbg_write_compression_hdr(pdbg_init, &temp_buff, dbg_buff);
+		if (rc) {
+			cudbg_put_buff(&temp_buff, dbg_buff);
+			return rc;
+		}
+
+		/* Restore back the actual size and release */
+		temp_buff.size = CUDBG_CHUNK_SIZE;
+		cudbg_put_buff(&temp_buff, dbg_buff);
+	}
+
 	bytes_left = tot_len;
 	while (bytes_left > 0) {
+		/* As mc size is huge, this loop will hold cpu for a longer time.
+		 * OS may think that the process is hanged and will generate
+		 * deadlock trace.
+		 * So yield the cpu regularly, after some iterations.
+		 */
+		yield_count++;
+		if (yield_count % CUDBG_YIELD_ITERATION == 0)
+			schedule();
+
 		bytes = min_t(unsigned long, bytes_left,
 			      (unsigned long)CUDBG_CHUNK_SIZE);
-		rc = cudbg_get_buff(dbg_buff, bytes, &temp_buff);
+
+		rc = cudbg_get_buff(pdbg_init, dbg_buff, bytes, &temp_buff);
 		if (rc)
 			return rc;
+
+		for (i = 0; i < ARRAY_SIZE(payload); i++) {
+			if (payload[i].exist &&
+			    bytes_read >= payload[i].start &&
+			    (bytes_read + bytes) <= payload[i].end) {
+				memset(temp_buff.data, 0, bytes);
+				/* TX and RX Payload regions
+				 * can't overlap.
+				 */
+				goto skip_read;
+			}
+		}
+
 		spin_lock(&padap->win0_lock);
 		rc = t4_memory_rw(padap, MEMWIN_NIC, mem_type,
 				  bytes_read, bytes,
@@ -432,9 +1016,25 @@ static int cudbg_read_fw_mem(struct cudbg_init *pdbg_init,
 			cudbg_put_buff(&temp_buff, dbg_buff);
 			return rc;
 		}
+
+skip_read:
 		bytes_left -= bytes;
 		bytes_read += bytes;
-		cudbg_write_and_release_buff(&temp_buff, dbg_buff);
+		if (pdbg_init->compress_type == CUDBG_COMPRESSION_NONE) {
+			rc = cudbg_write_and_release_buff(pdbg_init, &temp_buff,
+							  dbg_buff);
+			if (rc)
+				return rc;
+		} else {
+			rc = cudbg_do_compression(pdbg_init, &temp_buff,
+						  dbg_buff);
+			if (rc) {
+				cudbg_err->sys_err = rc;
+				cudbg_put_buff(&temp_buff, dbg_buff);
+				return rc;
+			}
+			cudbg_put_buff(&temp_buff, dbg_buff);
+		}
 	}
 	return rc;
 }
@@ -445,6 +1045,24 @@ static void cudbg_collect_mem_info(struct cudbg_init *pdbg_init,
 	struct adapter *padap = pdbg_init->adap;
 	u32 value;
 
+	value = t4_read_reg(padap, MA_EXT_MEMORY0_BAR_A);
+	value = EXT_MEM0_SIZE_G(value);
+	mem_info->size_mc0 = (u16)value;
+
+	value = t4_read_reg(padap, MA_EXT_MEMORY1_BAR_A);
+	value = EXT_MEM1_SIZE_G(value);
+	mem_info->size_mc1 = (u16)value;
+	/* In T6, there's no MC1. So, HMA shares mc1 address space */
+	mem_info->size_hma = (u16)value;
+
+	value = t4_read_reg(padap, MA_TARGET_MEM_ENABLE_A);
+	if (value & EXT_MEM0_ENABLE_F)
+		mem_info->mem_flag |= (1 << MC0_FLAG);
+	if (value & HMA_MUX_F)
+		mem_info->mem_flag |= (1 << HMA_FLAG);
+	else if (value & EXT_MEM1_ENABLE_F)
+		mem_info->mem_flag |= (1 << MC1_FLAG);
+
 	value = t4_read_reg(padap, MA_EDRAM0_BAR_A);
 	value = EDRAM0_SIZE_G(value);
 	mem_info->size_edc0 = (u16)value;
@@ -494,6 +1112,18 @@ static int cudbg_collect_mem_region(struct cudbg_init *pdbg_init,
 		flag = (1 << EDC1_FLAG);
 		size = cudbg_mbytes_to_bytes(mem_info.size_edc1);
 		break;
+	case MEM_MC0:
+		flag = (1 << MC0_FLAG);
+		size = cudbg_mbytes_to_bytes(mem_info.size_mc0);
+		break;
+	case MEM_MC1:
+		flag = (1 << MC1_FLAG);
+		size = cudbg_mbytes_to_bytes(mem_info.size_mc1);
+		break;
+	case MEM_HMA:
+		flag = (1 << HMA_FLAG);
+		size = cudbg_mbytes_to_bytes(mem_info.size_hma);
+		break;
 	default:
 		rc = CUDBG_STATUS_ENTITY_NOT_FOUND;
 		goto err;
@@ -528,6 +1158,30 @@ int cudbg_collect_edc1_meminfo(struct cudbg_init *pdbg_init,
 					MEM_EDC1);
 }
 
+int cudbg_collect_mc0_meminfo(struct cudbg_init *pdbg_init,
+			      struct cudbg_buffer *dbg_buff,
+			      struct cudbg_error *cudbg_err)
+{
+	return cudbg_collect_mem_region(pdbg_init, dbg_buff, cudbg_err,
+					MEM_MC0);
+}
+
+int cudbg_collect_mc1_meminfo(struct cudbg_init *pdbg_init,
+			      struct cudbg_buffer *dbg_buff,
+			      struct cudbg_error *cudbg_err)
+{
+	return cudbg_collect_mem_region(pdbg_init, dbg_buff, cudbg_err,
+					MEM_MC1);
+}
+
+int cudbg_collect_hma_meminfo(struct cudbg_init *pdbg_init,
+			      struct cudbg_buffer *dbg_buff,
+			      struct cudbg_error *cudbg_err)
+{
+	return cudbg_collect_mem_region(pdbg_init, dbg_buff, cudbg_err,
+					MEM_HMA);
+}
+
 int cudbg_collect_rss(struct cudbg_init *pdbg_init,
 		      struct cudbg_buffer *dbg_buff,
 		      struct cudbg_error *cudbg_err)
@@ -536,7 +1190,7 @@ int cudbg_collect_rss(struct cudbg_init *pdbg_init,
 	struct cudbg_buffer temp_buff = { 0 };
 	int rc;
 
-	rc = cudbg_get_buff(dbg_buff, RSS_NENTRIES * sizeof(u16), &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, RSS_NENTRIES * sizeof(u16), &temp_buff);
 	if (rc)
 		return rc;
 
@@ -546,8 +1200,50 @@ int cudbg_collect_rss(struct cudbg_init *pdbg_init,
 		cudbg_put_buff(&temp_buff, dbg_buff);
 		return rc;
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_rss_pf_config(struct cudbg_init *pdbg_init,
+				struct cudbg_buffer *dbg_buff,
+				struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	struct cudbg_rss_pf_conf *pfconf;
+	u32 rss_pf_map, rss_pf_mask;
+	int pf, rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, 8 * sizeof(struct cudbg_rss_pf_conf),
+			    &temp_buff);
+	if (rc)
+		return rc;
+
+	pfconf = (struct cudbg_rss_pf_conf *)temp_buff.data;
+	rss_pf_map = t4_read_rss_pf_map(padap, true);
+	rss_pf_mask = t4_read_rss_pf_mask(padap, true);
+	for (pf = 0; pf < 8; pf++) {
+		pfconf[pf].rss_pf_map = rss_pf_map;
+		pfconf[pf].rss_pf_mask = rss_pf_mask;
+		t4_read_rss_pf_config(padap, pf, &pfconf[pf].rss_pf_config,
+				      true);
+	}
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_rss_key(struct cudbg_init *pdbg_init,
+			  struct cudbg_buffer *dbg_buff,
+			  struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	int rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, 10 * sizeof(u32), &temp_buff);
+	if (rc)
+		return rc;
+
+	t4_read_rss_key(padap, (u32 *)temp_buff.data, true);
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_rss_vf_config(struct cudbg_init *pdbg_init,
@@ -560,7 +1256,7 @@ int cudbg_collect_rss_vf_config(struct cudbg_init *pdbg_init,
 	int vf, rc, vf_count;
 
 	vf_count = padap->params.arch.vfcount;
-	rc = cudbg_get_buff(dbg_buff,
+	rc = cudbg_get_buff(pdbg_init, dbg_buff,
 			    vf_count * sizeof(struct cudbg_rss_vf_conf),
 			    &temp_buff);
 	if (rc)
@@ -570,8 +1266,32 @@ int cudbg_collect_rss_vf_config(struct cudbg_init *pdbg_init,
 	for (vf = 0; vf < vf_count; vf++)
 		t4_read_rss_vf_config(padap, vf, &vfconf[vf].rss_vf_vfl,
 				      &vfconf[vf].rss_vf_vfh, true);
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_rss_config(struct cudbg_init *pdbg_init,
+			     struct cudbg_buffer *dbg_buff,
+			     struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	struct cudbg_rss_config *rss_conf;
+	int rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_rss_config),
+			    &temp_buff);
+	if (rc)
+		return rc;
+
+	rss_conf = (struct cudbg_rss_config *)temp_buff.data;
+	rss_conf->tp_rssconf = t4_read_reg(padap, TP_RSS_CONFIG_A);
+	rss_conf->tp_rssconf_tnl = t4_read_reg(padap, TP_RSS_CONFIG_TNL_A);
+	rss_conf->tp_rssconf_ofd = t4_read_reg(padap, TP_RSS_CONFIG_OFD_A);
+	rss_conf->tp_rssconf_syn = t4_read_reg(padap, TP_RSS_CONFIG_SYN_A);
+	rss_conf->tp_rssconf_vrt = t4_read_reg(padap, TP_RSS_CONFIG_VRT_A);
+	rss_conf->tp_rssconf_cng = t4_read_reg(padap, TP_RSS_CONFIG_CNG_A);
+	rss_conf->chip = padap->params.chip;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_path_mtu(struct cudbg_init *pdbg_init,
@@ -582,13 +1302,33 @@ int cudbg_collect_path_mtu(struct cudbg_init *pdbg_init,
 	struct cudbg_buffer temp_buff = { 0 };
 	int rc;
 
-	rc = cudbg_get_buff(dbg_buff, NMTUS * sizeof(u16), &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, NMTUS * sizeof(u16), &temp_buff);
 	if (rc)
 		return rc;
 
 	t4_read_mtu_tbl(padap, (u16 *)temp_buff.data, NULL);
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_sw_state(struct cudbg_init *pdbg_init,
+			   struct cudbg_buffer *dbg_buff,
+			   struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	struct cudbg_sw_state *swstate;
+	int rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_sw_state),
+			    &temp_buff);
+	if (rc)
+		return rc;
+
+	swstate = (struct cudbg_sw_state *)temp_buff.data;
+	swstate->fw_state = t4_read_reg(padap, PCIE_FW_A);
+	strcpy(swstate->caller_string, "ETHTOOL");
+	swstate->os_type = CUDBG_OS_TYPE_LINUX;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_pm_stats(struct cudbg_init *pdbg_init,
@@ -600,7 +1340,7 @@ int cudbg_collect_pm_stats(struct cudbg_init *pdbg_init,
 	struct cudbg_pm_stats *pm_stats_buff;
 	int rc;
 
-	rc = cudbg_get_buff(dbg_buff, sizeof(struct cudbg_pm_stats),
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_pm_stats),
 			    &temp_buff);
 	if (rc)
 		return rc;
@@ -608,8 +1348,7 @@ int cudbg_collect_pm_stats(struct cudbg_init *pdbg_init,
 	pm_stats_buff = (struct cudbg_pm_stats *)temp_buff.data;
 	t4_pmtx_get_stats(padap, pm_stats_buff->tx_cnt, pm_stats_buff->tx_cyc);
 	t4_pmrx_get_stats(padap, pm_stats_buff->rx_cnt, pm_stats_buff->rx_cyc);
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_hw_sched(struct cudbg_init *pdbg_init,
@@ -624,7 +1363,7 @@ int cudbg_collect_hw_sched(struct cudbg_init *pdbg_init,
 	if (!padap->params.vpd.cclk)
 		return CUDBG_STATUS_CCLK_NOT_DEFINED;
 
-	rc = cudbg_get_buff(dbg_buff, sizeof(struct cudbg_hw_sched),
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_hw_sched),
 			    &temp_buff);
 	hw_sched_buff = (struct cudbg_hw_sched *)temp_buff.data;
 	hw_sched_buff->map = t4_read_reg(padap, TP_TX_MOD_QUEUE_REQ_MAP_A);
@@ -633,8 +1372,91 @@ int cudbg_collect_hw_sched(struct cudbg_init *pdbg_init,
 	for (i = 0; i < NTX_SCHED; ++i)
 		t4_get_tx_sched(padap, i, &hw_sched_buff->kbps[i],
 				&hw_sched_buff->ipg[i], true);
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_tcp_stats(struct cudbg_init *pdbg_init,
+			    struct cudbg_buffer *dbg_buff,
+			    struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_tcp_stats *tcp_stats_buff;
+	struct cudbg_buffer temp_buff = { 0 };
+	int rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_tcp_stats),
+			    &temp_buff);
+	if (rc)
+		return rc;
+
+	tcp_stats_buff = (struct cudbg_tcp_stats *)temp_buff.data;
+	t4_tp_get_tcp_stats(padap, &tcp_stats_buff->v4,
+			    &tcp_stats_buff->v6, true);
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_tp_err_stats(struct cudbg_init *pdbg_init,
+			       struct cudbg_buffer *dbg_buff,
+			       struct cudbg_error *cudbg_err)
+{
+	struct cudbg_tp_err_stats *tp_err_stats_buff;
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	int rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_tp_err_stats),
+			    &temp_buff);
+	if (rc)
+		return rc;
+
+	tp_err_stats_buff = (struct cudbg_tp_err_stats *)temp_buff.data;
+	t4_tp_get_err_stats(padap, &tp_err_stats_buff->stats, true);
+	tp_err_stats_buff->nchan = padap->params.arch.nchan;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_fcoe_stats(struct cudbg_init *pdbg_init,
+			     struct cudbg_buffer *dbg_buff,
+			     struct cudbg_error *cudbg_err)
+{
+	struct cudbg_tp_fcoe_stats *tp_fcoe_stats_buff;
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	int rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_tp_fcoe_stats),
+			    &temp_buff);
+	if (rc)
+		return rc;
+
+	tp_fcoe_stats_buff = (struct cudbg_tp_fcoe_stats *)temp_buff.data;
+	t4_get_fcoe_stats(padap, 0, &tp_fcoe_stats_buff->stats[0], true);
+	t4_get_fcoe_stats(padap, 1, &tp_fcoe_stats_buff->stats[1], true);
+	if (padap->params.arch.nchan == NCHAN) {
+		t4_get_fcoe_stats(padap, 2, &tp_fcoe_stats_buff->stats[2],
+				  true);
+		t4_get_fcoe_stats(padap, 3, &tp_fcoe_stats_buff->stats[3],
+				  true);
+	}
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_rdma_stats(struct cudbg_init *pdbg_init,
+			     struct cudbg_buffer *dbg_buff,
+			     struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct tp_rdma_stats *rdma_stats_buff;
+	struct cudbg_buffer temp_buff = { 0 };
+	int rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct tp_rdma_stats), &temp_buff);
+	if (rc)
+		return rc;
+
+	rdma_stats_buff = (struct tp_rdma_stats *)temp_buff.data;
+	t4_tp_get_rdma_stats(padap, rdma_stats_buff, true);
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_tp_indirect(struct cudbg_init *pdbg_init,
@@ -658,7 +1480,7 @@ int cudbg_collect_tp_indirect(struct cudbg_init *pdbg_init,
 
 	n = n / (IREG_NUM_ELEM * sizeof(u32));
 	size = sizeof(struct ireg_buf) * n;
-	rc = cudbg_get_buff(dbg_buff, size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
 	if (rc)
 		return rc;
 
@@ -747,8 +1569,7 @@ int cudbg_collect_tp_indirect(struct cudbg_init *pdbg_init,
 			       tp_pio->ireg_local_offset, true);
 		ch_tp_pio++;
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_sge_indirect(struct cudbg_init *pdbg_init,
@@ -760,29 +1581,94 @@ int cudbg_collect_sge_indirect(struct cudbg_init *pdbg_init,
 	struct ireg_buf *ch_sge_dbg;
 	int i, rc;
 
-	rc = cudbg_get_buff(dbg_buff, sizeof(*ch_sge_dbg) * 2, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(*ch_sge_dbg) * 2, &temp_buff);
+	if (rc)
+		return rc;
+
+	ch_sge_dbg = (struct ireg_buf *)temp_buff.data;
+	for (i = 0; i < 2; i++) {
+		struct ireg_field *sge_pio = &ch_sge_dbg->tp_pio;
+		u32 *buff = ch_sge_dbg->outbuf;
+
+		sge_pio->ireg_addr = t5_sge_dbg_index_array[i][0];
+		sge_pio->ireg_data = t5_sge_dbg_index_array[i][1];
+		sge_pio->ireg_local_offset = t5_sge_dbg_index_array[i][2];
+		sge_pio->ireg_offset_range = t5_sge_dbg_index_array[i][3];
+		t4_read_indirect(padap,
+				 sge_pio->ireg_addr,
+				 sge_pio->ireg_data,
+				 buff,
+				 sge_pio->ireg_offset_range,
+				 sge_pio->ireg_local_offset);
+		ch_sge_dbg++;
+	}
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_cpl_stats(struct cudbg_init *pdbg_init,
+			    struct cudbg_buffer *dbg_buff,
+			    struct cudbg_error *cudbg_err)
+{
+	struct cudbg_tp_cpl_stats *tp_cpl_stats_buff;
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	int rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_tp_cpl_stats),
+			    &temp_buff);
+	if (rc)
+		return rc;
+
+	tp_cpl_stats_buff = (struct cudbg_tp_cpl_stats *)temp_buff.data;
+	tp_cpl_stats_buff->nchan = padap->params.arch.nchan;
+	t4_tp_get_cpl_stats(padap, &tp_cpl_stats_buff->stats, true);
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_ddp_stats(struct cudbg_init *pdbg_init,
+			    struct cudbg_buffer *dbg_buff,
+			    struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct tp_usm_stats *tp_usm_stats_buff;
+	struct cudbg_buffer temp_buff = { 0 };
+	int rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct tp_usm_stats), &temp_buff);
+	if (rc)
+		return rc;
+
+	tp_usm_stats_buff = (struct tp_usm_stats *)temp_buff.data;
+	t4_get_usm_stats(padap, tp_usm_stats_buff, true);
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_wc_stats(struct cudbg_init *pdbg_init,
+			   struct cudbg_buffer *dbg_buff,
+			   struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	struct cudbg_wc_stats *wc_stats_buff;
+	u32 val1, val2;
+	int rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_wc_stats),
+			    &temp_buff);
 	if (rc)
 		return rc;
 
-	ch_sge_dbg = (struct ireg_buf *)temp_buff.data;
-	for (i = 0; i < 2; i++) {
-		struct ireg_field *sge_pio = &ch_sge_dbg->tp_pio;
-		u32 *buff = ch_sge_dbg->outbuf;
-
-		sge_pio->ireg_addr = t5_sge_dbg_index_array[i][0];
-		sge_pio->ireg_data = t5_sge_dbg_index_array[i][1];
-		sge_pio->ireg_local_offset = t5_sge_dbg_index_array[i][2];
-		sge_pio->ireg_offset_range = t5_sge_dbg_index_array[i][3];
-		t4_read_indirect(padap,
-				 sge_pio->ireg_addr,
-				 sge_pio->ireg_data,
-				 buff,
-				 sge_pio->ireg_offset_range,
-				 sge_pio->ireg_local_offset);
-		ch_sge_dbg++;
+	wc_stats_buff = (struct cudbg_wc_stats *)temp_buff.data;
+	if (!is_t4(padap->params.chip)) {
+		val1 = t4_read_reg(padap, SGE_STAT_TOTAL_A);
+		val2 = t4_read_reg(padap, SGE_STAT_MATCH_A);
+		wc_stats_buff->wr_cl_success = val1 - val2;
+		wc_stats_buff->wr_cl_fail = val2;
+	} else {
+		wc_stats_buff->wr_cl_success = 0;
+		wc_stats_buff->wr_cl_fail = 0;
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_ulprx_la(struct cudbg_init *pdbg_init,
@@ -794,7 +1680,7 @@ int cudbg_collect_ulprx_la(struct cudbg_init *pdbg_init,
 	struct cudbg_ulprx_la *ulprx_la_buff;
 	int rc;
 
-	rc = cudbg_get_buff(dbg_buff, sizeof(struct cudbg_ulprx_la),
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_ulprx_la),
 			    &temp_buff);
 	if (rc)
 		return rc;
@@ -802,8 +1688,39 @@ int cudbg_collect_ulprx_la(struct cudbg_init *pdbg_init,
 	ulprx_la_buff = (struct cudbg_ulprx_la *)temp_buff.data;
 	t4_ulprx_read_la(padap, (u32 *)ulprx_la_buff->data);
 	ulprx_la_buff->size = ULPRX_LA_SIZE;
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_lb_stats(struct cudbg_init *pdbg_init,
+			   struct cudbg_buffer *dbg_buff,
+			   struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	struct cudbg_lb_stats *lb_stats_buff;
+	struct lb_port_stats *tmp_stats;
+	u32 i, n, size;
+	int rc;
+
+	rc = cudbg_get_port_count(pdbg_init);
+	if (rc < 0)
+		return rc;
+
+	n = rc;
+	size = sizeof(struct cudbg_lb_stats) +
+	       n * sizeof(struct lb_port_stats);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
+	if (rc)
+		return rc;
+
+	lb_stats_buff = (struct cudbg_lb_stats *)temp_buff.data;
+	lb_stats_buff->nchan = n;
+	tmp_stats = lb_stats_buff->s;
+	for (i = 0; i < n; i += 2, tmp_stats += 2) {
+		t4_get_lb_stats(padap, i, tmp_stats);
+		t4_get_lb_stats(padap, i + 1, tmp_stats+1);
+	}
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_tp_la(struct cudbg_init *pdbg_init,
@@ -816,15 +1733,38 @@ int cudbg_collect_tp_la(struct cudbg_init *pdbg_init,
 	int size, rc;
 
 	size = sizeof(struct cudbg_tp_la) + TPLA_SIZE *  sizeof(u64);
-	rc = cudbg_get_buff(dbg_buff, size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
 	if (rc)
 		return rc;
 
 	tp_la_buff = (struct cudbg_tp_la *)temp_buff.data;
 	tp_la_buff->mode = DBGLAMODE_G(t4_read_reg(padap, TP_DBG_LA_CONFIG_A));
 	t4_tp_read_la(padap, (u64 *)tp_la_buff->data, NULL);
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_meminfo(struct cudbg_init *pdbg_init,
+			  struct cudbg_buffer *dbg_buff,
+			  struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	struct cudbg_meminfo *meminfo_buff;
+	int rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_meminfo), &temp_buff);
+	if (rc)
+		return rc;
+
+	meminfo_buff = (struct cudbg_meminfo *)temp_buff.data;
+	rc = cudbg_fill_meminfo(padap, meminfo_buff);
+	if (rc) {
+		cudbg_err->sys_err = rc;
+		cudbg_put_buff(&temp_buff, dbg_buff);
+		return rc;
+	}
+
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_cim_pif_la(struct cudbg_init *pdbg_init,
@@ -838,7 +1778,7 @@ int cudbg_collect_cim_pif_la(struct cudbg_init *pdbg_init,
 
 	size = sizeof(struct cudbg_cim_pif_la) +
 	       2 * CIM_PIFLA_SIZE * 6 * sizeof(u32);
-	rc = cudbg_get_buff(dbg_buff, size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
 	if (rc)
 		return rc;
 
@@ -847,8 +1787,7 @@ int cudbg_collect_cim_pif_la(struct cudbg_init *pdbg_init,
 	t4_cim_read_pif_la(padap, (u32 *)cim_pif_la_buff->data,
 			   (u32 *)cim_pif_la_buff->data + 6 * CIM_PIFLA_SIZE,
 			   NULL, NULL);
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_clk_info(struct cudbg_init *pdbg_init,
@@ -864,7 +1803,7 @@ int cudbg_collect_clk_info(struct cudbg_init *pdbg_init,
 	if (!padap->params.vpd.cclk)
 		return CUDBG_STATUS_CCLK_NOT_DEFINED;
 
-	rc = cudbg_get_buff(dbg_buff, sizeof(struct cudbg_clk_info),
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_clk_info),
 			    &temp_buff);
 	if (rc)
 		return rc;
@@ -896,8 +1835,38 @@ int cudbg_collect_clk_info(struct cudbg_init *pdbg_init,
 	clk_info_buff->finwait2_timer =
 		tp_tick_us * t4_read_reg(padap, TP_FINWAIT2_TIMER_A);
 
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_macstats(struct cudbg_init *pdbg_init,
+			   struct cudbg_buffer *dbg_buff,
+			   struct cudbg_error *cudbg_err)
+{
+	struct cudbg_mac_stats_rev1 *mac_stats_buff;
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	u32 i, n;
+	int rc;
+
+	rc = cudbg_get_port_count(pdbg_init);
+	if (rc < 0)
+		return rc;
+
+	n = rc;
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_mac_stats_rev1),
+			    &temp_buff);
+	if (rc)
+		return rc;
+
+	mac_stats_buff = (struct cudbg_mac_stats_rev1 *)temp_buff.data;
+	mac_stats_buff->ver_hdr.signature = CUDBG_ENTITY_SIGNATURE;
+	mac_stats_buff->ver_hdr.revision = CUDBG_MAC_STATS_REV;
+	mac_stats_buff->ver_hdr.size = sizeof(struct cudbg_mac_stats_rev1) -
+				       sizeof(struct cudbg_ver_hdr);
+	mac_stats_buff->port_count = n;
+	for (i = 0; i <  mac_stats_buff->port_count; i++)
+		t4_get_port_stats(padap, i, &mac_stats_buff->stats[i]);
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_pcie_indirect(struct cudbg_init *pdbg_init,
@@ -912,7 +1881,7 @@ int cudbg_collect_pcie_indirect(struct cudbg_init *pdbg_init,
 
 	n = sizeof(t5_pcie_pdbg_array) / (IREG_NUM_ELEM * sizeof(u32));
 	size = sizeof(struct ireg_buf) * n * 2;
-	rc = cudbg_get_buff(dbg_buff, size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
 	if (rc)
 		return rc;
 
@@ -953,8 +1922,7 @@ int cudbg_collect_pcie_indirect(struct cudbg_init *pdbg_init,
 				 pcie_pio->ireg_local_offset);
 		ch_pcie++;
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_pm_indirect(struct cudbg_init *pdbg_init,
@@ -969,7 +1937,7 @@ int cudbg_collect_pm_indirect(struct cudbg_init *pdbg_init,
 
 	n = sizeof(t5_pm_rx_array) / (IREG_NUM_ELEM * sizeof(u32));
 	size = sizeof(struct ireg_buf) * n * 2;
-	rc = cudbg_get_buff(dbg_buff, size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
 	if (rc)
 		return rc;
 
@@ -1010,8 +1978,108 @@ int cudbg_collect_pm_indirect(struct cudbg_init *pdbg_init,
 				 pm_pio->ireg_local_offset);
 		ch_pm++;
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_full(struct cudbg_init *pdbg_init,
+		       struct cudbg_buffer *dbg_buff,
+		       struct cudbg_error *cudbg_err)
+{
+	u32 reg_addr, reg_data, reg_local_offset, reg_offset_range;
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	int rc, nreg = 0;
+	u32 *sp;
+
+	/* Collect Registers:
+	 * TP_DBG_SCHED_TX (0x7e40 + 0x6a),
+	 * TP_DBG_SCHED_RX (0x7e40 + 0x6b),
+	 * TP_DBG_CSIDE_INT (0x7e40 + 0x23f),
+	 * TP_DBG_ESIDE_INT (0x7e40 + 0x148),
+	 * PCIE_CDEBUG_INDEX[AppData0] (0x5a10 + 2),
+	 * PCIE_CDEBUG_INDEX[AppData1] (0x5a10 + 3)  This is for T6
+	 * SGE_DEBUG_DATA_HIGH_INDEX_10 (0x12a8)
+	 **/
+
+	if (is_t5(padap->params.chip))
+		nreg = 6;
+	else if (is_t6(padap->params.chip))
+		nreg = 7;
+
+	temp_buff.size = nreg * sizeof(u32);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, temp_buff.size, &temp_buff);
+	if (rc)
+		return rc;
+
+	sp = (u32 *)temp_buff.data;
+
+	/* TP_DBG_SCHED_TX */
+	reg_local_offset = t5_tp_pio_array[3][2] + 0xa;
+	reg_offset_range = 1;
+	t4_tp_pio_read(padap, sp, reg_offset_range, reg_local_offset, true);
+	sp++;
+
+	/* TP_DBG_SCHED_RX */
+	reg_local_offset = t5_tp_pio_array[3][2] + 0xb;
+	reg_offset_range = 1;
+	t4_tp_pio_read(padap, sp, reg_offset_range, reg_local_offset, true);
+	sp++;
+
+	/* TP_DBG_CSIDE_INT */
+	reg_local_offset = t5_tp_pio_array[9][2] + 0xf;
+	reg_offset_range = 1;
+	t4_tp_pio_read(padap, sp, reg_offset_range, reg_local_offset, true);
+	sp++;
+
+	/* TP_DBG_ESIDE_INT */
+	reg_local_offset = t5_tp_pio_array[8][2] + 3;
+	reg_offset_range = 1;
+	t4_tp_pio_read(padap, sp, reg_offset_range, reg_local_offset, true);
+	sp++;
+
+	/* PCIE_CDEBUG_INDEX[AppData0] */
+	reg_addr = t5_pcie_cdbg_array[0][0];
+	reg_data = t5_pcie_cdbg_array[0][1];
+	reg_local_offset = t5_pcie_cdbg_array[0][2] + 2;
+	reg_offset_range = 1;
+	t4_read_indirect(padap, reg_addr, reg_data, sp, reg_offset_range,
+			 reg_local_offset);
+	sp++;
+
+	if (is_t6(padap->params.chip)) {
+		/* PCIE_CDEBUG_INDEX[AppData1] */
+		reg_addr = t5_pcie_cdbg_array[0][0];
+		reg_data = t5_pcie_cdbg_array[0][1];
+		reg_local_offset = t5_pcie_cdbg_array[0][2] + 3;
+		reg_offset_range = 1;
+		t4_read_indirect(padap, reg_addr, reg_data, sp,
+				 reg_offset_range, reg_local_offset);
+		sp++;
+	}
+
+	/* SGE_DEBUG_DATA_HIGH_INDEX_10 */
+	*sp = t4_read_reg(padap, SGE_DEBUG_DATA_HIGH_INDEX_10_A);
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_tx_rate(struct cudbg_init *pdbg_init,
+			  struct cudbg_buffer *dbg_buff,
+			  struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	struct cudbg_tx_rate *tx_rate;
+	int rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_tx_rate),
+			    &temp_buff);
+	if (rc)
+		return rc;
+
+	tx_rate = (struct cudbg_tx_rate *)temp_buff.data;
+	t4_get_chan_txrate(padap, tx_rate->nrate, tx_rate->orate);
+	tx_rate->nchan = padap->params.arch.nchan;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_tid(struct cudbg_init *pdbg_init,
@@ -1025,7 +2093,7 @@ int cudbg_collect_tid(struct cudbg_init *pdbg_init,
 	u32 para[2], val[2];
 	int rc;
 
-	rc = cudbg_get_buff(dbg_buff, sizeof(struct cudbg_tid_info_region_rev1),
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_tid_info_region_rev1),
 			    &temp_buff);
 	if (rc)
 		return rc;
@@ -1095,8 +2163,275 @@ int cudbg_collect_tid(struct cudbg_init *pdbg_init,
 
 #undef FW_PARAM_PFVF_A
 
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_pcie_config(struct cudbg_init *pdbg_init,
+			      struct cudbg_buffer *dbg_buff,
+			      struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	u32 size, *value, j;
+	int i, rc, n;
+
+	size = sizeof(u32) * CUDBG_NUM_PCIE_CONFIG_REGS;
+	n = sizeof(t5_pcie_config_array) / (2 * sizeof(u32));
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
+	if (rc)
+		return rc;
+
+	value = (u32 *)temp_buff.data;
+	for (i = 0; i < n; i++) {
+		for (j = t5_pcie_config_array[i][0];
+		     j <= t5_pcie_config_array[i][1]; j += 4) {
+			t4_hw_pci_read_cfg4(padap, j, value);
+			value++;
+		}
+	}
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+/**
+ * Get EGRESS, INGRESS, FLM, and CNM max qid.
+ *
+ * For EGRESS and INGRESS, do the following calculation.
+ * max_qid = (DBQ/IMSG context region size in bytes) /
+ *	     (size of context in bytes).
+ *
+ * For FLM, do the following calculation.
+ * max_qid = (FLM cache region size in bytes) /
+ *	     ((number of pointers cached in EDRAM) * 8 (bytes per pointer)).
+ *
+ * There's a 1-to-1 mapping between FLM and CNM if there's no header splitting
+ * enabled; i.e., max CNM qid is equal to max FLM qid. However, if header
+ * splitting is enabled, then max CNM qid is half of max FLM qid.
+ */
+static int cudbg_get_max_ctxt_qid(struct adapter *padap,
+				  struct cudbg_meminfo *meminfo,
+				  u32 *max_ctx_qid, u8 nelem)
+{
+	u32 i, idx, found = 0;
+
+	if (nelem != (CTXT_CNM + 1))
+		return -EINVAL;
+
+	for (i = 0; i < meminfo->mem_c; i++) {
+		if (meminfo->mem[i].idx >= ARRAY_SIZE(cudbg_region))
+			continue;                        /* skip holes */
+
+		idx = meminfo->mem[i].idx;
+		/* Get DBQ, IMSG, and FLM context region size */
+		if (idx <= CTXT_FLM) {
+			if (!(meminfo->mem[i].limit))
+				meminfo->mem[i].limit =
+					i < meminfo->mem_c - 1 ?
+					meminfo->mem[i + 1].base - 1 : ~0;
+
+			if (idx < CTXT_FLM) {
+				/* Get EGRESS and INGRESS max qid. */
+				max_ctx_qid[idx] = (meminfo->mem[i].limit -
+						    meminfo->mem[i].base + 1) /
+						   SGE_CTXT_SIZE;
+				found++;
+			} else {
+				/* Get FLM and CNM max qid. */
+				u32 value, edram_ptr_count;
+				u8 bytes_per_ptr = 8;
+				u8 nohdr;
+
+				value = t4_read_reg(padap, SGE_FLM_CFG_A);
+
+				/* Check if header splitting is enabled. */
+				nohdr = (value >> NOHDR_S) & 1U;
+
+				/* Get the number of pointers in EDRAM per
+				 * qid in units of 32.
+				 */
+				edram_ptr_count = 32 *
+						  (1U << EDRAMPTRCNT_G(value));
+
+				/* EDRAMPTRCNT value of 3 is reserved.
+				 * So don't exceed 128.
+				 */
+				if (edram_ptr_count > 128)
+					edram_ptr_count = 128;
+
+				max_ctx_qid[idx] = (meminfo->mem[i].limit -
+						    meminfo->mem[i].base + 1) /
+						   (edram_ptr_count *
+						    bytes_per_ptr);
+				found++;
+
+				/* CNM has 1-to-1 mapping with FLM.
+				 * However, if header splitting is enabled,
+				 * then max CNM qid is half of max FLM qid.
+				 */
+				max_ctx_qid[CTXT_CNM] = nohdr ?
+							max_ctx_qid[idx] :
+							max_ctx_qid[idx] >> 1;
+
+				/* One more increment for CNM */
+				found++;
+			}
+		}
+		if (found == nelem)
+			break;
+	}
+
+	/* Sanity check. Ensure the values are within known max. */
+	max_ctx_qid[CTXT_EGRESS] = min_t(u32, max_ctx_qid[CTXT_EGRESS],
+					 CTXTQID_M);
+	max_ctx_qid[CTXT_INGRESS] = min_t(u32, max_ctx_qid[CTXT_INGRESS],
+					  CUDBG_MAX_INGRESS_QIDS);
+	max_ctx_qid[CTXT_FLM] = min_t(u32, max_ctx_qid[CTXT_FLM],
+				      CUDBG_MAX_FL_QIDS);
+	max_ctx_qid[CTXT_CNM] = min_t(u32, max_ctx_qid[CTXT_CNM],
+				      CUDBG_MAX_CNM_QIDS);
+	return 0;
+}
+
+int cudbg_dump_context_size(struct adapter *padap)
+{
+	u32 max_ctx_qid[CTXT_CNM + 1];
+	struct cudbg_meminfo meminfo;
+	u32 i, size = 0;
+	int rc;
+
+	rc = cudbg_fill_meminfo(padap, &meminfo);
+	if (rc)
+		return rc;
+
+	/* Get max valid qid for each type of queue */
+	rc = cudbg_get_max_ctxt_qid(padap, &meminfo, max_ctx_qid, CTXT_CNM + 1);
+	if (rc)
+		return rc;
+
+	/* There are four types of queues. Collect context upto max
+	 * qid of each type of queue.
+	 */
+	for (i = CTXT_EGRESS; i <= CTXT_CNM; i++)
+		size += sizeof(struct cudbg_ch_cntxt) * max_ctx_qid[i];
+
+	return size;
+}
+
+static void cudbg_read_sge_ctxt(struct cudbg_init *pdbg_init, u32 cid,
+				enum ctxt_type ctype, u32 *data)
+{
+	struct adapter *padap = pdbg_init->adap;
+	int rc = -1;
+
+	if (is_fw_attached(pdbg_init))
+		rc = t4_sge_ctxt_rd(padap, padap->mbox, cid, ctype, data);
+	if (rc)
+		t4_sge_ctxt_rd_bd(padap, cid, ctype, data);
+}
+
+static int cudbg_sge_ctxt_check_valid(u32 *buf, int type)
+{
+	int index, bit, bit_pos = 0;
+
+	switch (type) {
+	case CTXT_EGRESS:
+		bit_pos = 176;
+		break;
+	case CTXT_INGRESS:
+		bit_pos = 141;
+		break;
+	case CTXT_FLM:
+		bit_pos = 89;
+		break;
+	}
+	index = bit_pos / 32;
+	bit =  bit_pos % 32;
+	return buf[index] & (1U << bit);
+}
+
+int cudbg_collect_dump_context(struct cudbg_init *pdbg_init,
+			       struct cudbg_buffer *dbg_buff,
+			       struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	u32 max_ctx_qid[CTXT_CNM + 1];
+	struct cudbg_meminfo meminfo;
+	u32 size = 0, total_size = 0;
+	struct cudbg_ch_cntxt *buff;
+	u32 i, j, qid_count = 0;
+	bool limit_qid = false;
+	int rc;
+
+	rc = cudbg_dump_context_size(padap);
+	if (rc <= 0)
+		return rc;
+
+	size = rc;
+
+	rc = cudbg_fill_meminfo(padap, &meminfo);
+	if (rc)
+		return rc;
+
+	/* Get max valid qid for each type of queue */
+	rc = cudbg_get_max_ctxt_qid(padap, &meminfo, max_ctx_qid, CTXT_CNM + 1);
+	if (rc)
+		return rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
+	if (rc == CUDBG_STATUS_NO_MEM) {
+		/* Not enough scratch Memory available.
+		 * Collect context of at least CUDBG_LOWMEM_MAX_CTXT_QIDS
+		 * for each queue type.
+		 */
+		size = 0;
+		for (i = CTXT_EGRESS; i <= CTXT_CNM; i++)
+			size += sizeof(struct cudbg_ch_cntxt) *
+				CUDBG_LOWMEM_MAX_CTXT_QIDS;
+
+		limit_qid = true;
+		rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
+		if (rc)
+			return rc;
+	}
+
+	buff = (struct cudbg_ch_cntxt *)temp_buff.data;
+	/* Collect context data */
+	for (i = CTXT_EGRESS; i <= CTXT_FLM; i++) {
+		qid_count = 0;
+		for (j = 0; j < max_ctx_qid[i]; j++) {
+			cudbg_read_sge_ctxt(pdbg_init, j, i, buff->data);
+
+			rc = cudbg_sge_ctxt_check_valid(buff->data, i);
+			if (rc) {
+				buff->cntxt_type = i;
+				buff->cntxt_id = j;
+				buff++;
+				total_size += sizeof(struct cudbg_ch_cntxt);
+
+				if (i == CTXT_FLM) {
+					cudbg_read_sge_ctxt(pdbg_init, j,
+							    CTXT_CNM,
+							    buff->data);
+					buff->cntxt_type = CTXT_CNM;
+					buff->cntxt_id = j;
+					buff++;
+					total_size +=
+						sizeof(struct cudbg_ch_cntxt);
+				}
+				qid_count++;
+			}
+
+			/* If there's not enough space to collect more qids,
+			 * then bail and move on to next queue type.
+			 */
+			if (limit_qid &&
+			    qid_count >= CUDBG_LOWMEM_MAX_CTXT_QIDS)
+				break;
+		}
+	}
+
+	temp_buff.size = total_size;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 static inline void cudbg_tcamxy2valmask(u64 x, u64 y, u8 *addr, u64 *mask)
@@ -1257,7 +2592,7 @@ int cudbg_collect_mps_tcam(struct cudbg_init *pdbg_init,
 
 	n = padap->params.arch.mps_tcam_size;
 	size = sizeof(struct cudbg_mps_tcam) * n;
-	rc = cudbg_get_buff(dbg_buff, size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
 	if (rc)
 		return rc;
 
@@ -1269,6 +2604,10 @@ int cudbg_collect_mps_tcam(struct cudbg_init *pdbg_init,
 			cudbg_put_buff(&temp_buff, dbg_buff);
 			return rc;
 		}
+
+		if (i && !tcam->idx)
+			continue;
+
 		total_size += sizeof(struct cudbg_mps_tcam);
 		tcam++;
 	}
@@ -1279,8 +2618,8 @@ int cudbg_collect_mps_tcam(struct cudbg_init *pdbg_init,
 		cudbg_put_buff(&temp_buff, dbg_buff);
 		return rc;
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	temp_buff.size = total_size;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_vpd_data(struct cudbg_init *pdbg_init,
@@ -1290,26 +2629,215 @@ int cudbg_collect_vpd_data(struct cudbg_init *pdbg_init,
 	struct adapter *padap = pdbg_init->adap;
 	struct cudbg_buffer temp_buff = { 0 };
 	struct cudbg_vpd_data *vpd_data;
+	struct vpd_params vpd = { 0 };
+	u32 fw_vers = 0;
 	int rc;
 
-	rc = cudbg_get_buff(dbg_buff, sizeof(struct cudbg_vpd_data),
+	t4_get_vpd_params(padap, &vpd);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_vpd_data),
 			    &temp_buff);
 	if (rc)
 		return rc;
 
 	vpd_data = (struct cudbg_vpd_data *)temp_buff.data;
-	memcpy(vpd_data->sn, padap->params.vpd.sn, SERNUM_LEN + 1);
-	memcpy(vpd_data->bn, padap->params.vpd.pn, PN_LEN + 1);
-	memcpy(vpd_data->na, padap->params.vpd.na, MACADDR_LEN + 1);
-	memcpy(vpd_data->mn, padap->params.vpd.id, ID_LEN + 1);
-	vpd_data->scfg_vers = padap->params.scfg_vers;
-	vpd_data->vpd_vers = padap->params.vpd_vers;
-	vpd_data->fw_major = FW_HDR_FW_VER_MAJOR_G(padap->params.fw_vers);
-	vpd_data->fw_minor = FW_HDR_FW_VER_MINOR_G(padap->params.fw_vers);
-	vpd_data->fw_micro = FW_HDR_FW_VER_MICRO_G(padap->params.fw_vers);
-	vpd_data->fw_build = FW_HDR_FW_VER_BUILD_G(padap->params.fw_vers);
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	memcpy(vpd_data->sn, vpd.sn, SERNUM_LEN + 1);
+	memcpy(vpd_data->bn, vpd.pn, PN_LEN + 1);
+	memcpy(vpd_data->na, vpd.na, MACADDR_LEN + 1);
+	memcpy(vpd_data->mn, vpd.id, ID_LEN + 1);
+	t4_get_scfg_version(padap, &vpd_data->scfg_vers);
+	t4_get_vpd_version(padap, &vpd_data->vpd_vers);
+	t4_get_fw_version(padap, &fw_vers);
+	vpd_data->fw_major = FW_HDR_FW_VER_MAJOR_G(fw_vers);
+	vpd_data->fw_minor = FW_HDR_FW_VER_MINOR_G(fw_vers);
+	vpd_data->fw_micro = FW_HDR_FW_VER_MICRO_G(fw_vers);
+	vpd_data->fw_build = FW_HDR_FW_VER_BUILD_G(fw_vers);
+
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+static int cudbg_read_tid(struct cudbg_init *pdbg_init, u32 tid,
+			  struct cudbg_tid_data *tid_data)
+{
+	struct adapter *padap = pdbg_init->adap;
+	int i, cmd_retry = 8;
+	u32 val;
+
+	/* Fill REQ_DATA regs with 0's */
+	for (i = 0; i < CUDBG_NUM_REQ_REGS; i++)
+		t4_write_reg(padap, LE_DB_DBGI_REQ_DATA_A + (i << 2), 0);
+
+	/* Write DBIG command */
+	val = (0x4 << DBGICMD_S) | tid;
+	t4_write_reg(padap, LE_DB_DBGI_REQ_TCAM_CMD_A, val);
+	tid_data->dbig_cmd = val;
+
+	val = 0;
+	val |= 1 << DBGICMDSTRT_S;
+	val |= 1;  /* LE mode */
+	t4_write_reg(padap, LE_DB_DBGI_CONFIG_A, val);
+	tid_data->dbig_conf = val;
+
+	/* Poll the DBGICMDBUSY bit */
+	val = 1;
+	while (val) {
+		val = t4_read_reg(padap, LE_DB_DBGI_CONFIG_A);
+		val = (val >> DBGICMDBUSY_S) & 1;
+		cmd_retry--;
+		if (!cmd_retry) {
+			dev_err(padap->pdev_dev, "%s(): Timeout waiting for non-busy\n",
+				__func__);
+			return CUDBG_SYSTEM_ERROR;
+		}
+	}
+
+	/* Check RESP status */
+	val = 0;
+	val = t4_read_reg(padap, LE_DB_DBGI_RSP_STATUS_A);
+	tid_data->dbig_rsp_stat = val;
+	if (!(val & 1)) {
+		dev_err(padap->pdev_dev, "%s(): DBGI command failed\n",
+			__func__);
+		return CUDBG_SYSTEM_ERROR;
+	}
+
+	/* Read RESP data */
+	for (i = 0; i < CUDBG_NUM_REQ_REGS; i++)
+		tid_data->data[i] = t4_read_reg(padap,
+						LE_DB_DBGI_RSP_DATA_A +
+						(i << 2));
+
+	tid_data->tid = tid;
+	return 0;
+}
+
+static int cudbg_get_le_type(u32 tid, struct cudbg_tcam tcam_region)
+{
+	int type = LE_ET_UNKNOWN;
+
+	if (tid < tcam_region.server_start)
+		type = LE_ET_TCAM_CON;
+	else if (tid < tcam_region.filter_start)
+		type = LE_ET_TCAM_SERVER;
+	else if (tid < tcam_region.clip_start)
+		type = LE_ET_TCAM_FILTER;
+	else if (tid < tcam_region.routing_start)
+		type = LE_ET_TCAM_CLIP;
+	else if (tid < tcam_region.tid_hash_base)
+		type = LE_ET_TCAM_ROUTING;
+	else if (tid < tcam_region.max_tid)
+		type = LE_ET_HASH_CON;
+	else
+		type = LE_ET_INVALID_TID;
+
+	return type;
+}
+
+static int cudbg_is_ipv6_entry(struct cudbg_tid_data *tid_data,
+			       struct cudbg_tcam tcam_region)
+{
+	int le_type;
+	int ipv6 = 0;
+
+	le_type = cudbg_get_le_type(tid_data->tid, tcam_region);
+	if (tid_data->tid & 1) {
+		return 0;
+	} else {
+		if (le_type == LE_ET_HASH_CON) {
+			ipv6 = tid_data->data[16] & 0x8000;
+		} else if (le_type == LE_ET_TCAM_CON) {
+			ipv6 = tid_data->data[16] & 0x8000;
+			if (ipv6)
+				ipv6 = (tid_data->data[9] == 0x00C00000);
+		} else {
+			ipv6 = 0;
+		}
+	}
+	return ipv6;
+}
+
+void cudbg_fill_le_tcam_info(struct adapter *padap,
+			     struct cudbg_tcam *tcam_region)
+{
+	u32 value;
+
+	/* Get the LE regions */
+	value = t4_read_reg(padap, LE_DB_TID_HASHBASE_A); /* hash base index */
+	tcam_region->tid_hash_base = value;
+
+	/* Get routing table index */
+	value = t4_read_reg(padap, LE_DB_ROUTING_TABLE_INDEX_A);
+	tcam_region->routing_start = value;
+
+	/*Get clip table index */
+	value = t4_read_reg(padap, LE_DB_CLIP_TABLE_INDEX_A);
+	tcam_region->clip_start = value;
+
+	/* Get filter table index */
+	value = t4_read_reg(padap, LE_DB_FILTER_TABLE_INDEX_A);
+	tcam_region->filter_start = value;
+
+	/* Get server table index */
+	value = t4_read_reg(padap, LE_DB_SERVER_INDEX_A);
+	tcam_region->server_start = value;
+
+	/* Check whether hash is enabled and calculate the max tids */
+	value = t4_read_reg(padap, LE_DB_CONFIG_A);
+	if ((value >> HASHEN_S) & 1) {
+		value = t4_read_reg(padap, LE_DB_HASH_CONFIG_A);
+		if (CHELSIO_CHIP_VERSION(padap->params.chip) > CHELSIO_T5)
+			tcam_region->max_tid = (value & 0xFFFFF) +
+					       tcam_region->tid_hash_base;
+		else {	    /* for T5 */
+			value = HASHTIDSIZE_G(value);
+			value = 1 << value;
+			tcam_region->max_tid = value +
+					       tcam_region->tid_hash_base;
+		}
+	} else { /* hash not enabled */
+		tcam_region->max_tid = CUDBG_MAX_TCAM_TID;
+	}
+}
+
+int cudbg_collect_le_tcam(struct cudbg_init *pdbg_init,
+			  struct cudbg_buffer *dbg_buff,
+			  struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	struct cudbg_tcam tcam_region = { 0 };
+	struct cudbg_tid_data *tid_data;
+	u32 bytes = 0;
+	int rc, size;
+	u32 i;
+
+	cudbg_fill_le_tcam_info(padap, &tcam_region);
+
+	size = sizeof(struct cudbg_tid_data) * tcam_region.max_tid;
+	size += sizeof(struct cudbg_tcam);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
+	if (rc)
+		return rc;
+
+	memcpy(temp_buff.data, &tcam_region, sizeof(struct cudbg_tcam));
+	bytes = sizeof(struct cudbg_tcam);
+	tid_data = (struct cudbg_tid_data *)(temp_buff.data + bytes);
+	/* read all tid */
+	for (i = 0; i < tcam_region.max_tid; ) {
+		rc = cudbg_read_tid(pdbg_init, i, tid_data);
+		if (rc) {
+			cudbg_err->sys_err = rc;
+			cudbg_put_buff(&temp_buff, dbg_buff);
+			return rc;
+		}
+
+		/* ipv6 takes two tids */
+		cudbg_is_ipv6_entry(tid_data, tcam_region) ? i += 2 : i++;
+
+		tid_data++;
+		bytes += sizeof(struct cudbg_tid_data);
+	}
+
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_cctrl(struct cudbg_init *pdbg_init,
@@ -1322,13 +2850,12 @@ int cudbg_collect_cctrl(struct cudbg_init *pdbg_init,
 	int rc;
 
 	size = sizeof(u16) * NMTUS * NCCTRL_WIN;
-	rc = cudbg_get_buff(dbg_buff, size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
 	if (rc)
 		return rc;
 
 	t4_read_cong_tbl(padap, (void *)temp_buff.data);
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_ma_indirect(struct cudbg_init *pdbg_init,
@@ -1346,7 +2873,7 @@ int cudbg_collect_ma_indirect(struct cudbg_init *pdbg_init,
 
 	n = sizeof(t6_ma_ireg_array) / (IREG_NUM_ELEM * sizeof(u32));
 	size = sizeof(struct ireg_buf) * n * 2;
-	rc = cudbg_get_buff(dbg_buff, size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
 	if (rc)
 		return rc;
 
@@ -1382,8 +2909,7 @@ int cudbg_collect_ma_indirect(struct cudbg_init *pdbg_init,
 		}
 		ma_indr++;
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_ulptx_la(struct cudbg_init *pdbg_init,
@@ -1396,7 +2922,7 @@ int cudbg_collect_ulptx_la(struct cudbg_init *pdbg_init,
 	u32 i, j;
 	int rc;
 
-	rc = cudbg_get_buff(dbg_buff, sizeof(struct cudbg_ulptx_la),
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_ulptx_la),
 			    &temp_buff);
 	if (rc)
 		return rc;
@@ -1417,8 +2943,7 @@ int cudbg_collect_ulptx_la(struct cudbg_init *pdbg_init,
 				t4_read_reg(padap,
 					    ULP_TX_LA_RDDATA_0_A + 0x10 * i);
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_up_cim_indirect(struct cudbg_init *pdbg_init,
@@ -1433,7 +2958,7 @@ int cudbg_collect_up_cim_indirect(struct cudbg_init *pdbg_init,
 
 	n = sizeof(t5_up_cim_reg_array) / (IREG_NUM_ELEM * sizeof(u32));
 	size = sizeof(struct ireg_buf) * n;
-	rc = cudbg_get_buff(dbg_buff, size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
 	if (rc)
 		return rc;
 
@@ -1461,13 +2986,13 @@ int cudbg_collect_up_cim_indirect(struct cudbg_init *pdbg_init,
 		rc = t4_cim_read(padap, up_cim_reg->ireg_local_offset,
 				 up_cim_reg->ireg_offset_range, buff);
 		if (rc) {
+			cudbg_err->sys_err = rc;
 			cudbg_put_buff(&temp_buff, dbg_buff);
 			return rc;
 		}
 		up_cim++;
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_pbt_tables(struct cudbg_init *pdbg_init,
@@ -1480,7 +3005,7 @@ int cudbg_collect_pbt_tables(struct cudbg_init *pdbg_init,
 	int i, rc;
 	u32 addr;
 
-	rc = cudbg_get_buff(dbg_buff, sizeof(struct cudbg_pbt_tables),
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(struct cudbg_pbt_tables),
 			    &temp_buff);
 	if (rc)
 		return rc;
@@ -1534,8 +3059,7 @@ int cudbg_collect_pbt_tables(struct cudbg_init *pdbg_init,
 			return rc;
 		}
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_mbox_log(struct cudbg_init *pdbg_init,
@@ -1556,7 +3080,7 @@ int cudbg_collect_mbox_log(struct cudbg_init *pdbg_init,
 	log = padap->mbox_log;
 	mbox_cmds = padap->mbox_log->size;
 	size = sizeof(struct cudbg_mbox_log) * mbox_cmds;
-	rc = cudbg_get_buff(dbg_buff, size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
 	if (rc)
 		return rc;
 
@@ -1579,8 +3103,7 @@ int cudbg_collect_mbox_log(struct cudbg_init *pdbg_init,
 		}
 		mboxlog++;
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
 
 int cudbg_collect_hma_indirect(struct cudbg_init *pdbg_init,
@@ -1598,7 +3121,7 @@ int cudbg_collect_hma_indirect(struct cudbg_init *pdbg_init,
 
 	n = sizeof(t6_hma_ireg_array) / (IREG_NUM_ELEM * sizeof(u32));
 	size = sizeof(struct ireg_buf) * n;
-	rc = cudbg_get_buff(dbg_buff, size, &temp_buff);
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, size, &temp_buff);
 	if (rc)
 		return rc;
 
@@ -1616,6 +3139,31 @@ int cudbg_collect_hma_indirect(struct cudbg_init *pdbg_init,
 				 hma_fli->ireg_local_offset);
 		hma_indr++;
 	}
-	cudbg_write_and_release_buff(&temp_buff, dbg_buff);
-	return rc;
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
+}
+
+int cudbg_collect_upload(struct cudbg_init *pdbg_init,
+			 struct cudbg_buffer *dbg_buff,
+			 struct cudbg_error *cudbg_err)
+{
+	struct adapter *padap = pdbg_init->adap;
+	struct cudbg_buffer temp_buff = { 0 };
+	u32 param, *value;
+	int rc;
+
+	rc = cudbg_get_buff(pdbg_init, dbg_buff, sizeof(u32), &temp_buff);
+	if (rc)
+		return rc;
+
+	value = (u32 *)temp_buff.data;
+	param = (FW_PARAMS_MNEM_V(FW_PARAMS_MNEM_DEV) |
+		 FW_PARAMS_PARAM_X_V(FW_PARAMS_PARAM_DEV_LOAD));
+	rc = t4_query_params(padap, padap->mbox, padap->pf, 0, 1,
+			     &param, value);
+	if (rc < 0) {
+		cudbg_err->sys_err = CUDBG_SYSTEM_ERROR;
+		cudbg_put_buff(&temp_buff, dbg_buff);
+		return rc;
+	}
+	return cudbg_write_and_release_buff(pdbg_init, &temp_buff, dbg_buff);
 }
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cudbg_lib.h b/drivers/net/ethernet/chelsio/cxgb4/cudbg_lib.h
index 230ba88a..a28dee85 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cudbg_lib.h
+++ b/drivers/net/ethernet/chelsio/cxgb4/cudbg_lib.h
@@ -18,6 +18,8 @@
 #ifndef __CUDBG_LIB_H__
 #define __CUDBG_LIB_H__
 
+#define CUDBG_YIELD_ITERATION 200
+
 int cudbg_collect_reg_dump(struct cudbg_init *pdbg_init,
 			   struct cudbg_buffer *dbg_buff,
 			   struct cudbg_error *cudbg_err);
@@ -75,33 +77,81 @@ int cudbg_collect_edc0_meminfo(struct cudbg_init *pdbg_init,
 int cudbg_collect_edc1_meminfo(struct cudbg_init *pdbg_init,
 			       struct cudbg_buffer *dbg_buff,
 			       struct cudbg_error *cudbg_err);
+int cudbg_collect_mc0_meminfo(struct cudbg_init *pdbg_init,
+			      struct cudbg_buffer *dbg_buff,
+			      struct cudbg_error *cudbg_err);
+int cudbg_collect_mc1_meminfo(struct cudbg_init *pdbg_init,
+			      struct cudbg_buffer *dbg_buff,
+			      struct cudbg_error *cudbg_err);
+int cudbg_collect_hma_meminfo(struct cudbg_init *pdbg_init,
+			      struct cudbg_buffer *dbg_buff,
+			      struct cudbg_error *cudbg_err);
 int cudbg_collect_rss(struct cudbg_init *pdbg_init,
 		      struct cudbg_buffer *dbg_buff,
 		      struct cudbg_error *cudbg_err);
+int cudbg_collect_rss_pf_config(struct cudbg_init *pdbg_init,
+				struct cudbg_buffer *dbg_buff,
+				struct cudbg_error *cudbg_err);
+int cudbg_collect_rss_key(struct cudbg_init *pdbg_init,
+			  struct cudbg_buffer *dbg_buff,
+			  struct cudbg_error *cudbg_err);
 int cudbg_collect_rss_vf_config(struct cudbg_init *pdbg_init,
 				struct cudbg_buffer *dbg_buff,
 				struct cudbg_error *cudbg_err);
+int cudbg_collect_rss_config(struct cudbg_init *pdbg_init,
+			     struct cudbg_buffer *dbg_buff,
+			     struct cudbg_error *cudbg_err);
 int cudbg_collect_tp_indirect(struct cudbg_init *pdbg_init,
 			      struct cudbg_buffer *dbg_buff,
 			      struct cudbg_error *cudbg_err);
 int cudbg_collect_path_mtu(struct cudbg_init *pdbg_init,
 			   struct cudbg_buffer *dbg_buff,
 			   struct cudbg_error *cudbg_err);
+int cudbg_collect_sw_state(struct cudbg_init *pdbg_init,
+			   struct cudbg_buffer *dbg_buff,
+			   struct cudbg_error *cudbg_err);
 int cudbg_collect_pm_stats(struct cudbg_init *pdbg_init,
 			   struct cudbg_buffer *dbg_buff,
 			   struct cudbg_error *cudbg_err);
 int cudbg_collect_hw_sched(struct cudbg_init *pdbg_init,
 			   struct cudbg_buffer *dbg_buff,
 			   struct cudbg_error *cudbg_err);
+int cudbg_collect_tcp_stats(struct cudbg_init *pdbg_init,
+			    struct cudbg_buffer *dbg_buff,
+			    struct cudbg_error *cudbg_err);
+int cudbg_collect_tp_err_stats(struct cudbg_init *pdbg_init,
+			       struct cudbg_buffer *dbg_buff,
+			       struct cudbg_error *cudbg_err);
+int cudbg_collect_fcoe_stats(struct cudbg_init *pdbg_init,
+			     struct cudbg_buffer *dbg_buff,
+			     struct cudbg_error *cudbg_err);
+int cudbg_collect_rdma_stats(struct cudbg_init *pdbg_init,
+			     struct cudbg_buffer *dbg_buff,
+			     struct cudbg_error *cudbg_er);
 int cudbg_collect_sge_indirect(struct cudbg_init *pdbg_init,
 			       struct cudbg_buffer *dbg_buff,
 			       struct cudbg_error *cudbg_err);
+int cudbg_collect_cpl_stats(struct cudbg_init *pdbg_init,
+			    struct cudbg_buffer *dbg_buff,
+			    struct cudbg_error *cudbg_err);
+int cudbg_collect_ddp_stats(struct cudbg_init *pdbg_init,
+			    struct cudbg_buffer *dbg_buff,
+			    struct cudbg_error *cudbg_err);
+int cudbg_collect_wc_stats(struct cudbg_init *pdbg_init,
+			   struct cudbg_buffer *dbg_buff,
+			   struct cudbg_error *cudbg_err);
 int cudbg_collect_ulprx_la(struct cudbg_init *pdbg_init,
 			   struct cudbg_buffer *dbg_buff,
 			   struct cudbg_error *cudbg_err);
+int cudbg_collect_lb_stats(struct cudbg_init *pdbg_init,
+			   struct cudbg_buffer *dbg_buff,
+			   struct cudbg_error *cudbg_err);
 int cudbg_collect_tp_la(struct cudbg_init *pdbg_init,
 			struct cudbg_buffer *dbg_buff,
 			struct cudbg_error *cudbg_err);
+int cudbg_collect_meminfo(struct cudbg_init *pdbg_init,
+			  struct cudbg_buffer *dbg_buff,
+			  struct cudbg_error *cudbg_err);
 int cudbg_collect_cim_pif_la(struct cudbg_init *pdbg_init,
 			     struct cudbg_buffer *dbg_buff,
 			     struct cudbg_error *cudbg_err);
@@ -114,21 +164,39 @@ int cudbg_collect_obq_sge_rx_q0(struct cudbg_init *pdbg_init,
 int cudbg_collect_obq_sge_rx_q1(struct cudbg_init *pdbg_init,
 				struct cudbg_buffer *dbg_buff,
 				struct cudbg_error *cudbg_err);
+int cudbg_collect_macstats(struct cudbg_init *pdbg_init,
+			   struct cudbg_buffer *dbg_buff,
+			   struct cudbg_error *cudbg_err);
 int cudbg_collect_pcie_indirect(struct cudbg_init *pdbg_init,
 				struct cudbg_buffer *dbg_buff,
 				struct cudbg_error *cudbg_err);
 int cudbg_collect_pm_indirect(struct cudbg_init *pdbg_init,
 			      struct cudbg_buffer *dbg_buff,
 			      struct cudbg_error *cudbg_err);
+int cudbg_collect_full(struct cudbg_init *pdbg_init,
+		       struct cudbg_buffer *dbg_buff,
+		       struct cudbg_error *cudbg_err);
+int cudbg_collect_tx_rate(struct cudbg_init *pdbg_init,
+			  struct cudbg_buffer *dbg_buff,
+			  struct cudbg_error *cudbg_err);
 int cudbg_collect_tid(struct cudbg_init *pdbg_init,
 		      struct cudbg_buffer *dbg_buff,
 		      struct cudbg_error *cudbg_err);
+int cudbg_collect_pcie_config(struct cudbg_init *pdbg_init,
+			      struct cudbg_buffer *dbg_buff,
+			      struct cudbg_error *cudbg_err);
+int cudbg_collect_dump_context(struct cudbg_init *pdbg_init,
+			       struct cudbg_buffer *dbg_buff,
+			       struct cudbg_error *cudbg_err);
 int cudbg_collect_mps_tcam(struct cudbg_init *pdbg_init,
 			   struct cudbg_buffer *dbg_buff,
 			   struct cudbg_error *cudbg_err);
 int cudbg_collect_vpd_data(struct cudbg_init *pdbg_init,
 			   struct cudbg_buffer *dbg_buff,
 			   struct cudbg_error *cudbg_err);
+int cudbg_collect_le_tcam(struct cudbg_init *pdbg_init,
+			  struct cudbg_buffer *dbg_buff,
+			  struct cudbg_error *cudbg_err);
 int cudbg_collect_cctrl(struct cudbg_init *pdbg_init,
 			struct cudbg_buffer *dbg_buff,
 			struct cudbg_error *cudbg_err);
@@ -150,9 +218,21 @@ int cudbg_collect_mbox_log(struct cudbg_init *pdbg_init,
 int cudbg_collect_hma_indirect(struct cudbg_init *pdbg_init,
 			       struct cudbg_buffer *dbg_buff,
 			       struct cudbg_error *cudbg_err);
+int cudbg_collect_upload(struct cudbg_init *pdbg_init,
+			 struct cudbg_buffer *dbg_buff,
+			 struct cudbg_error *cudbg_err);
 
 struct cudbg_entity_hdr *cudbg_get_entity_hdr(void *outbuf, int i);
 void cudbg_align_debug_buffer(struct cudbg_buffer *dbg_buff,
 			      struct cudbg_entity_hdr *entity_hdr);
+int cudbg_wr_entity_to_flash(struct cudbg_init *pdbg_init,
+			     struct cudbg_buffer *dbg_buff,
+			     struct cudbg_entity_hdr *entity_hdr);
+
 u32 cudbg_cim_obq_size(struct adapter *padap, int qid);
+int cudbg_dump_context_size(struct adapter *padap);
+
+struct cudbg_tcam;
+void cudbg_fill_le_tcam_info(struct adapter *padap,
+			     struct cudbg_tcam *tcam_region);
 #endif /* __CUDBG_LIB_H__ */
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cudbg_lib_common.h b/drivers/net/ethernet/chelsio/cxgb4/cudbg_lib_common.h
index 24b33f28..0b6d2303 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cudbg_lib_common.h
+++ b/drivers/net/ethernet/chelsio/cxgb4/cudbg_lib_common.h
@@ -19,6 +19,11 @@
 #define __CUDBG_LIB_COMMON_H__
 
 #define CUDBG_SIGNATURE 67856866 /* CUDB in ascii */
+#define CUDBG_FL_SIGNATURE 0x4355464c /* CUFL in ascii */
+
+#define CUDBG_FL_MAJOR_VERSION 1
+#define CUDBG_FL_MINOR_VERSION 1
+#define CUDBG_FL_BUILD_VERSION 0
 
 enum cudbg_dump_type {
 	CUDBG_DUMP_TYPE_MINI = 1,
@@ -75,13 +80,42 @@ struct cudbg_error {
 	int app_err;
 };
 
+struct cudbg_flash_hdr {
+	u32 signature;
+	u8 major_ver;
+	u8 minor_ver;
+	u8 build_ver;
+	u8 res;
+	u64 timestamp;
+	u64 time_res;
+	u32 hdr_len;
+	u32 data_len;
+	u32 hdr_flags;
+	u32 sec_seq_no;
+	u32 reserved[22];
+};
+
 #define CDUMP_MAX_COMP_BUF_SIZE ((64 * 1024) - 1)
 #define CUDBG_CHUNK_SIZE ((CDUMP_MAX_COMP_BUF_SIZE / 1024) * 1024)
 
-int cudbg_get_buff(struct cudbg_buffer *pdbg_buff, u32 size,
+int cudbg_get_buff(struct cudbg_init *pdbg_init,
+		   struct cudbg_buffer *pdbg_buff, u32 size,
 		   struct cudbg_buffer *pin_buff);
+void cudbg_get_compress_buff(struct cudbg_init *pdbg_init,
+			     struct cudbg_buffer *pdbg_buff,
+			     struct cudbg_buffer *pin_buff);
 void cudbg_put_buff(struct cudbg_buffer *pin_buff,
 		    struct cudbg_buffer *pdbg_buff);
 void cudbg_update_buff(struct cudbg_buffer *pin_buff,
 		       struct cudbg_buffer *pout_buff);
+int cudbg_write_flash(struct cudbg_init *pdbg_init,
+		      struct cudbg_buffer *dbg_buff,
+		      u32 start_offset, u32 cur_entity_hdr_offset,
+		      u32 cur_entity_size);
+int cudbg_write_compression_hdr(struct cudbg_init *pdbg_init,
+				struct cudbg_buffer *pin_buff,
+				struct cudbg_buffer *pout_buff);
+int cudbg_compress_buff(struct cudbg_init *pdbg_init,
+			struct cudbg_buffer *pin_buff,
+			struct cudbg_buffer *pout_buff);
 #endif /* __CUDBG_LIB_COMMON_H__ */
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_cudbg.c b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_cudbg.c
index 7373617d..38c31c11 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_cudbg.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_cudbg.c
@@ -19,10 +19,14 @@
 #include "cxgb4.h"
 #include "cxgb4_cudbg.h"
 #include "cudbg_entity.h"
+#include "fastlz_common.h"
 
 static const struct cxgb4_collect_entity cxgb4_collect_mem_dump[] = {
 	{ CUDBG_EDC0, cudbg_collect_edc0_meminfo },
 	{ CUDBG_EDC1, cudbg_collect_edc1_meminfo },
+	{ CUDBG_MC0, cudbg_collect_mc0_meminfo },
+	{ CUDBG_MC1, cudbg_collect_mc1_meminfo },
+	{ CUDBG_HMA, cudbg_collect_hma_meminfo },
 };
 
 static const struct cxgb4_collect_entity cxgb4_collect_hw_dump[] = {
@@ -45,29 +49,65 @@ static const struct cxgb4_collect_entity cxgb4_collect_hw_dump[] = {
 	{ CUDBG_CIM_OBQ_SGE, cudbg_collect_cim_obq_sge },
 	{ CUDBG_CIM_OBQ_NCSI, cudbg_collect_cim_obq_ncsi },
 	{ CUDBG_RSS, cudbg_collect_rss },
+	{ CUDBG_RSS_PF_CONF, cudbg_collect_rss_pf_config },
+	{ CUDBG_RSS_KEY, cudbg_collect_rss_key },
 	{ CUDBG_RSS_VF_CONF, cudbg_collect_rss_vf_config },
+	{ CUDBG_RSS_CONF, cudbg_collect_rss_config },
 	{ CUDBG_PATH_MTU, cudbg_collect_path_mtu },
+	{ CUDBG_SW_STATE, cudbg_collect_sw_state },
 	{ CUDBG_PM_STATS, cudbg_collect_pm_stats },
 	{ CUDBG_HW_SCHED, cudbg_collect_hw_sched },
+	{ CUDBG_TCP_STATS, cudbg_collect_tcp_stats },
+	{ CUDBG_TP_ERR_STATS, cudbg_collect_tp_err_stats },
+	{ CUDBG_FCOE_STATS, cudbg_collect_fcoe_stats },
+	{ CUDBG_RDMA_STATS, cudbg_collect_rdma_stats },
 	{ CUDBG_TP_INDIRECT, cudbg_collect_tp_indirect },
 	{ CUDBG_SGE_INDIRECT, cudbg_collect_sge_indirect },
+	{ CUDBG_CPL_STATS, cudbg_collect_cpl_stats },
+	{ CUDBG_DDP_STATS, cudbg_collect_ddp_stats },
+	{ CUDBG_WC_STATS, cudbg_collect_wc_stats },
 	{ CUDBG_ULPRX_LA, cudbg_collect_ulprx_la },
+	{ CUDBG_LB_STATS, cudbg_collect_lb_stats },
 	{ CUDBG_TP_LA, cudbg_collect_tp_la },
+	{ CUDBG_MEMINFO, cudbg_collect_meminfo },
 	{ CUDBG_CIM_PIF_LA, cudbg_collect_cim_pif_la },
 	{ CUDBG_CLK, cudbg_collect_clk_info },
 	{ CUDBG_CIM_OBQ_RXQ0, cudbg_collect_obq_sge_rx_q0 },
 	{ CUDBG_CIM_OBQ_RXQ1, cudbg_collect_obq_sge_rx_q1 },
+	{ CUDBG_MAC_STATS, cudbg_collect_macstats },
 	{ CUDBG_PCIE_INDIRECT, cudbg_collect_pcie_indirect },
 	{ CUDBG_PM_INDIRECT, cudbg_collect_pm_indirect },
+	{ CUDBG_FULL, cudbg_collect_full },
+	{ CUDBG_TX_RATE, cudbg_collect_tx_rate },
 	{ CUDBG_TID_INFO, cudbg_collect_tid },
+	{ CUDBG_PCIE_CONFIG, cudbg_collect_pcie_config },
+	{ CUDBG_DUMP_CONTEXT, cudbg_collect_dump_context },
 	{ CUDBG_MPS_TCAM, cudbg_collect_mps_tcam },
 	{ CUDBG_VPD_DATA, cudbg_collect_vpd_data },
+	{ CUDBG_LE_TCAM, cudbg_collect_le_tcam },
 	{ CUDBG_CCTRL, cudbg_collect_cctrl },
 	{ CUDBG_MA_INDIRECT, cudbg_collect_ma_indirect },
 	{ CUDBG_ULPTX_LA, cudbg_collect_ulptx_la },
 	{ CUDBG_UP_CIM_INDIRECT, cudbg_collect_up_cim_indirect },
 	{ CUDBG_PBT_TABLE, cudbg_collect_pbt_tables },
 	{ CUDBG_HMA_INDIRECT, cudbg_collect_hma_indirect },
+	{ CUDBG_UPLOAD, cudbg_collect_upload },
+};
+
+static const char * cxgb4_entity_string[] = {
+	"all", "regdump", "devlog", "cimla", "cimmala", "cimqcfg",
+	"ibqtp0", "ibqtp1", "ibqulp", "ibqsge0", "ibqsge1", "ibqncsi",
+	"obqulp0", "obqulp1", "obqulp2", "obqulp3", "obqsge", "obqncsi",
+	"edc0", "edc1", "mc0", "mc1", "rss", "rss_pf_config", "rss_key",
+	"rss_vf_config", "rss_config", "pathmtu", "swstate", "wtp", "pmstats",
+	"hwsched", "tcpstats", "tperrstats", "fcoestats", "rdmastats",
+	"tpindirect", "sgeindirect", "cplstats", "ddpstats", "wcstats",
+	"ulprxla", "lbstats", "tpla", "meminfo", "cimpifla", "clk",
+	"obq_sge_rx_q0", "obq_sge_rx_q1", "macstats", "pcieindirect",
+	"pmindirect", "full", "txrate", "tidinfo", "pcieconfig",
+	"dumpcontext", "mpstcam", "vpddata", "letcam", "cctrl", "maindirect",
+	"ulptxla", "extentity", "upcimindirect", "pbttables",
+	"mboxlog", "hmaindirect", "hma", "upload",
 };
 
 static u32 cxgb4_get_entity_length(struct adapter *adap, u32 entity)
@@ -155,22 +195,73 @@ static u32 cxgb4_get_entity_length(struct adapter *adap, u32 entity)
 		}
 		len = cudbg_mbytes_to_bytes(len);
 		break;
+	case CUDBG_MC0:
+		value = t4_read_reg(adap, MA_TARGET_MEM_ENABLE_A);
+		if (value & EXT_MEM0_ENABLE_F) {
+			value = t4_read_reg(adap, MA_EXT_MEMORY0_BAR_A);
+			len = EXT_MEM0_SIZE_G(value);
+		}
+		len = cudbg_mbytes_to_bytes(len);
+		break;
+	case CUDBG_MC1:
+		value = t4_read_reg(adap, MA_TARGET_MEM_ENABLE_A);
+		if (value & EXT_MEM1_ENABLE_F) {
+			value = t4_read_reg(adap, MA_EXT_MEMORY1_BAR_A);
+			len = EXT_MEM1_SIZE_G(value);
+		}
+		len = cudbg_mbytes_to_bytes(len);
+		break;
+	case CUDBG_HMA:
+		value = t4_read_reg(adap, MA_TARGET_MEM_ENABLE_A);
+		if (value & HMA_MUX_F) {
+			/* In T6, there's no MC1.  So, HMA shares MC1
+			 * address space.
+			 */
+			value = t4_read_reg(adap, MA_EXT_MEMORY1_BAR_A);
+			len = EXT_MEM1_SIZE_G(value);
+		}
+		len = cudbg_mbytes_to_bytes(len);
+		break;
 	case CUDBG_RSS:
 		len = RSS_NENTRIES * sizeof(u16);
 		break;
+	case CUDBG_RSS_PF_CONF:
+		len = 8 * sizeof(struct cudbg_rss_pf_conf);
+		break;
+	case CUDBG_RSS_KEY:
+		len = 10 * sizeof(u32);
+		break;
 	case CUDBG_RSS_VF_CONF:
 		len = adap->params.arch.vfcount *
 		      sizeof(struct cudbg_rss_vf_conf);
 		break;
+	case CUDBG_RSS_CONF:
+		len = sizeof(struct cudbg_rss_config);
+		break;
 	case CUDBG_PATH_MTU:
 		len = NMTUS * sizeof(u16);
 		break;
+	case CUDBG_SW_STATE:
+		len = sizeof(struct cudbg_sw_state);
+		break;
 	case CUDBG_PM_STATS:
 		len = sizeof(struct cudbg_pm_stats);
 		break;
 	case CUDBG_HW_SCHED:
 		len = sizeof(struct cudbg_hw_sched);
 		break;
+	case CUDBG_TCP_STATS:
+		len = sizeof(struct cudbg_tcp_stats);
+		break;
+	case CUDBG_TP_ERR_STATS:
+		len = sizeof(struct cudbg_tp_err_stats);
+		break;
+	case CUDBG_FCOE_STATS:
+		len = sizeof(struct cudbg_tp_fcoe_stats);
+		break;
+	case CUDBG_RDMA_STATS:
+		len = sizeof(struct tp_rdma_stats);
+		break;
 	case CUDBG_TP_INDIRECT:
 		switch (CHELSIO_CHIP_VERSION(adap->params.chip)) {
 		case CHELSIO_T5:
@@ -192,12 +283,28 @@ static u32 cxgb4_get_entity_length(struct adapter *adap, u32 entity)
 	case CUDBG_SGE_INDIRECT:
 		len = sizeof(struct ireg_buf) * 2;
 		break;
+	case CUDBG_CPL_STATS:
+		len = sizeof(struct cudbg_tp_cpl_stats);
+		break;
+	case CUDBG_DDP_STATS:
+		len = sizeof(struct tp_usm_stats);
+		break;
+	case CUDBG_WC_STATS:
+		len = sizeof(struct cudbg_wc_stats);
+		break;
 	case CUDBG_ULPRX_LA:
 		len = sizeof(struct cudbg_ulprx_la);
 		break;
+	case CUDBG_LB_STATS:
+		len = sizeof(struct cudbg_lb_stats) + adap->params.nports *
+		      sizeof(struct lb_port_stats);
+		break;
 	case CUDBG_TP_LA:
 		len = sizeof(struct cudbg_tp_la) + TPLA_SIZE * sizeof(u64);
 		break;
+	case CUDBG_MEMINFO:
+		len = sizeof(struct cudbg_meminfo);
+		break;
 	case CUDBG_CIM_PIF_LA:
 		len = sizeof(struct cudbg_cim_pif_la);
 		len += 2 * CIM_PIFLA_SIZE * 6 * sizeof(u32);
@@ -205,6 +312,9 @@ static u32 cxgb4_get_entity_length(struct adapter *adap, u32 entity)
 	case CUDBG_CLK:
 		len = sizeof(struct cudbg_clk_info);
 		break;
+	case CUDBG_MAC_STATS:
+		len = sizeof(struct cudbg_mac_stats_rev1);
+		break;
 	case CUDBG_PCIE_INDIRECT:
 		n = sizeof(t5_pcie_pdbg_array) / (IREG_NUM_ELEM * sizeof(u32));
 		len = sizeof(struct ireg_buf) * n * 2;
@@ -213,9 +323,26 @@ static u32 cxgb4_get_entity_length(struct adapter *adap, u32 entity)
 		n = sizeof(t5_pm_rx_array) / (IREG_NUM_ELEM * sizeof(u32));
 		len = sizeof(struct ireg_buf) * n * 2;
 		break;
+	case CUDBG_FULL:
+		if (is_t5(adap->params.chip))
+			n = 6;
+		else if (is_t6(adap->params.chip))
+			n = 7;
+		len = n * sizeof(u32);
+		break;
+	case CUDBG_TX_RATE:
+		len = sizeof(struct cudbg_tx_rate);
+		break;
 	case CUDBG_TID_INFO:
 		len = sizeof(struct cudbg_tid_info_region_rev1);
 		break;
+	case CUDBG_PCIE_CONFIG:
+		len = sizeof(u32) * CUDBG_NUM_PCIE_CONFIG_REGS;
+		break;
+	case CUDBG_DUMP_CONTEXT:
+		n = cudbg_dump_context_size(adap);
+		len = n > 0 ? n : 0;
+		break;
 	case CUDBG_MPS_TCAM:
 		len = sizeof(struct cudbg_mps_tcam) *
 		      adap->params.arch.mps_tcam_size;
@@ -223,6 +350,14 @@ static u32 cxgb4_get_entity_length(struct adapter *adap, u32 entity)
 	case CUDBG_VPD_DATA:
 		len = sizeof(struct cudbg_vpd_data);
 		break;
+	case CUDBG_LE_TCAM: {
+		struct cudbg_tcam tcam_region = { 0 };
+
+		cudbg_fill_le_tcam_info(adap, &tcam_region);
+		len = sizeof(struct cudbg_tcam) +
+		      sizeof(struct cudbg_tid_data) * tcam_region.max_tid;
+		break;
+	}
 	case CUDBG_CCTRL:
 		len = sizeof(u16) * NMTUS * NCCTRL_WIN;
 		break;
@@ -253,6 +388,9 @@ static u32 cxgb4_get_entity_length(struct adapter *adap, u32 entity)
 			len = sizeof(struct ireg_buf) * n;
 		}
 		break;
+	case CUDBG_UPLOAD:
+		len = sizeof(u32);
+		break;
 	default:
 		break;
 	}
@@ -290,23 +428,30 @@ static void cxgb4_cudbg_collect_entity(struct cudbg_init *pdbg_init,
 	struct adapter *adap = pdbg_init->adap;
 	struct cudbg_error cudbg_err = { 0 };
 	struct cudbg_entity_hdr *entity_hdr;
+	struct cudbg_hdr *cudbg_hdr;
 	u32 entity_size, i;
 	u32 total_size = 0;
 	int ret;
 
+	cudbg_hdr = pdbg_init->outbuf;
 	for (i = 0; i < arr_size; i++) {
 		const struct cxgb4_collect_entity *e = &e_arr[i];
 
 		/* Skip entities that won't fit in output buffer */
 		entity_size = cxgb4_get_entity_length(adap, e->entity);
 		if (entity_size >
-		    pdbg_init->outbuf_size - *tot_size - total_size)
+		    pdbg_init->outbuf_size - *tot_size - total_size) {
+			dev_warn(adap->pdev_dev, "No space for entity %s, Skipping",
+				 cxgb4_entity_string[e->entity]);
 			continue;
+		}
 
 		entity_hdr = cudbg_get_entity_hdr(buf, e->entity);
 		entity_hdr->entity_type = e->entity;
 		entity_hdr->start_offset = dbg_buff->offset;
 		memset(&cudbg_err, 0, sizeof(struct cudbg_error));
+		dev_info(adap->pdev_dev, "Collecting debug entity %s",
+			 cxgb4_entity_string[e->entity]);
 		ret = e->collect_cb(pdbg_init, dbg_buff, &cudbg_err);
 		if (ret) {
 			entity_hdr->size = 0;
@@ -315,6 +460,9 @@ static void cxgb4_cudbg_collect_entity(struct cudbg_init *pdbg_init,
 			cudbg_align_debug_buffer(dbg_buff, entity_hdr);
 		}
 
+		if (ret)
+			dev_warn(adap->pdev_dev, "status: %d", ret);
+
 		/* Log error and continue with next entity */
 		if (cudbg_err.sys_err)
 			ret = CUDBG_SYSTEM_ERROR;
@@ -323,6 +471,16 @@ static void cxgb4_cudbg_collect_entity(struct cudbg_init *pdbg_init,
 		entity_hdr->sys_err = cudbg_err.sys_err;
 		entity_hdr->sys_warn = cudbg_err.sys_warn;
 		total_size += entity_hdr->size;
+		cudbg_hdr->data_len += entity_hdr->size;
+
+		if (!ret) {
+			if (pdbg_init->use_flash)
+				cudbg_wr_entity_to_flash(pdbg_init, dbg_buff,
+							 entity_hdr);
+			else
+				dev_info(adap->pdev_dev, "size: %u",
+					 entity_hdr->size);
+		}
 	}
 
 	*tot_size += total_size;
@@ -355,6 +513,7 @@ int cxgb4_cudbg_collect(struct adapter *adap, void *buf, u32 *buf_size,
 	cudbg_hdr->chip_ver = adap->params.chip;
 	cudbg_hdr->dump_type = CUDBG_DUMP_TYPE_MINI;
 	cudbg_hdr->compress_type = CUDBG_COMPRESSION_NONE;
+	cudbg_init.compress_type = CUDBG_COMPRESSION_NONE;
 
 	min_size = sizeof(struct cudbg_hdr) +
 		   sizeof(struct cudbg_entity_hdr) *
@@ -364,6 +523,7 @@ int cxgb4_cudbg_collect(struct adapter *adap, void *buf, u32 *buf_size,
 
 	dbg_buff.offset += min_size;
 	total_size = dbg_buff.offset;
+	cudbg_hdr->data_len = total_size;
 
 	if (flag & CXGB4_ETH_DUMP_HW)
 		cxgb4_cudbg_collect_entity(&cudbg_init, &dbg_buff,
@@ -379,7 +539,6 @@ int cxgb4_cudbg_collect(struct adapter *adap, void *buf, u32 *buf_size,
 					   buf,
 					   &total_size);
 
-	cudbg_hdr->data_len = total_size;
 	*buf_size = total_size;
 	return 0;
 }
@@ -390,3 +549,81 @@ void cxgb4_init_ethtool_dump(struct adapter *adapter)
 	adapter->eth_dump.version = adapter->params.fw_vers;
 	adapter->eth_dump.len = 0;
 }
+
+int cxgb4_cudbg_collect_panic(struct adapter *adap, void *buf, u32 buf_size)
+{
+	struct cudbg_init cudbg_init = { 0 };
+	struct cudbg_buffer dbg_buff = { 0 };
+	u32 size, min_size, total_size = 0;
+	struct cudbg_hdr *cudbg_hdr;
+	struct timespec ts;
+
+	size = buf_size;
+
+	cudbg_init.adap = adap;
+	cudbg_init.outbuf = buf;
+	cudbg_init.outbuf_size = size;
+	cudbg_init.use_flash = true;
+	getnstimeofday(&ts);
+	cudbg_init.time = ts.tv_sec;
+	cudbg_init.hash_table = t4_alloc_mem(sizeof(unsigned char *) *
+					     FASTLZ_HASH_SIZE);
+	if (!cudbg_init.hash_table)
+		return -ENOMEM;
+
+	/* Give extra CUDBG_BLOCK_SIZE for storing compression result */
+	cudbg_init.compress_buff = t4_alloc_mem(size + CUDBG_BLOCK_SIZE);
+	if (!cudbg_init.compress_buff)
+		goto free_mem;
+
+	cudbg_init.psec_info =
+		t4_alloc_mem(sizeof(struct cudbg_flash_sec_info));
+	if (!cudbg_init.psec_info)
+		goto free_mem;
+
+	dbg_buff.data = buf;
+	dbg_buff.size = size;
+	dbg_buff.offset = 0;
+
+	cudbg_hdr = (struct cudbg_hdr *)buf;
+	cudbg_hdr->signature = CUDBG_SIGNATURE;
+	cudbg_hdr->hdr_len = sizeof(struct cudbg_hdr);
+	cudbg_hdr->major_ver = CUDBG_MAJOR_VERSION;
+	cudbg_hdr->minor_ver = CUDBG_MINOR_VERSION;
+	cudbg_hdr->max_entities = CUDBG_MAX_ENTITY;
+	cudbg_hdr->chip_ver = adap->params.chip;
+
+	min_size = sizeof(struct cudbg_hdr) +
+		   sizeof(struct cudbg_entity_hdr) *
+		   cudbg_hdr->max_entities;
+	if (size < min_size) {
+		dev_info(adap->pdev_dev, "FAIL - Min buf size: %u required\n",
+			 min_size);
+		goto free_mem;
+	}
+
+	dbg_buff.offset += min_size;
+	total_size = dbg_buff.offset;
+	cudbg_hdr->data_len = total_size;
+
+	cxgb4_cudbg_collect_entity(&cudbg_init, &dbg_buff,
+				   cxgb4_collect_hw_dump,
+				   ARRAY_SIZE(cxgb4_collect_hw_dump),
+				   buf,
+				   &total_size);
+
+	cxgb4_cudbg_collect_entity(&cudbg_init, &dbg_buff,
+				   cxgb4_collect_mem_dump,
+				   ARRAY_SIZE(cxgb4_collect_mem_dump),
+				   buf,
+				   &total_size);
+
+free_mem:
+	if (cudbg_init.psec_info)
+		t4_free_mem(cudbg_init.psec_info);
+	if (cudbg_init.compress_buff)
+		t4_free_mem(cudbg_init.compress_buff);
+	if (cudbg_init.hash_table)
+		t4_free_mem(cudbg_init.hash_table);
+	return 0;
+}
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_cudbg.h b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_cudbg.h
index c099b5aa..216a1351 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_cudbg.h
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_cudbg.h
@@ -40,5 +40,6 @@ enum CXGB4_ETHTOOL_DUMP_FLAGS {
 u32 cxgb4_get_dump_length(struct adapter *adap, u32 flag);
 int cxgb4_cudbg_collect(struct adapter *adap, void *buf, u32 *buf_size,
 			u32 flag);
+int cxgb4_cudbg_collect_panic(struct adapter *adap, void *buf, u32 buf_size);
 void cxgb4_init_ethtool_dump(struct adapter *adapter);
 #endif /* __CXGB4_CUDBG_H__ */
diff --git a/drivers/net/ethernet/chelsio/cxgb4/fastlz.c b/drivers/net/ethernet/chelsio/cxgb4/fastlz.c
new file mode 100644
index 00000000..331d1ff1
--- /dev/null
+++ b/drivers/net/ethernet/chelsio/cxgb4/fastlz.c
@@ -0,0 +1,328 @@
+/*
+   FastLZ - lightning-fast lossless compression library
+
+   Copyright (C) 2007 Ariya Hidayat (ariya@kde.org)
+   Copyright (C) 2006 Ariya Hidayat (ariya@kde.org)
+   Copyright (C) 2005 Ariya Hidayat (ariya@kde.org)
+   Copyright (C) 2017 Chelsio Communications
+
+   Permission is hereby granted, free of charge, to any person obtaining a copy
+   of this software and associated documentation files (the "Software"), to deal
+   in the Software without restriction, including without limitation the rights
+   to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+   copies of the Software, and to permit persons to whom the Software is
+   furnished to do so, subject to the following conditions:
+
+   The above copyright notice and this permission notice shall be included in
+   all copies or substantial portions of the Software.
+
+   THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+   IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+   FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+   AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+   LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+   OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+   THE SOFTWARE.
+   */
+
+#include "fastlz_common.h"
+
+#if !defined(FASTLZ_COMPRESSOR)
+
+#undef FASTLZ_LEVEL
+#define FASTLZ_LEVEL 1
+
+#undef FASTLZ_COMPRESSOR
+#define FASTLZ_COMPRESSOR fastlz1_compress
+static FASTLZ_INLINE int FASTLZ_COMPRESSOR(unsigned char *hash_table,
+					   const void *input, int length,
+					   void *output);
+#include "fastlz.c"
+
+#undef FASTLZ_LEVEL
+#define FASTLZ_LEVEL 2
+
+#undef MAX_DISTANCE
+#define MAX_DISTANCE 8191
+#define MAX_FARDISTANCE (65535 + MAX_DISTANCE - 1)
+
+#undef FASTLZ_COMPRESSOR
+#define FASTLZ_COMPRESSOR fastlz2_compress
+static FASTLZ_INLINE int FASTLZ_COMPRESSOR(unsigned char *hash_table,
+					   const void *input, int length,
+					   void *output);
+#include "fastlz.c"
+
+int fastlz_compress(unsigned char *hash_table, const void *input, int length,
+		    void *output)
+{
+	/* for short block, choose fastlz1 */
+	if (length < 65536)
+		return fastlz1_compress(hash_table, input, length, output);
+
+	/* else... */
+	return fastlz2_compress(hash_table, input, length, output);
+}
+
+int fastlz_compress_level(unsigned char *hash_table, int level,
+			  const void *input, int length,
+			  void *output)
+{
+	if (level == 1)
+		return fastlz1_compress(hash_table, input, length, output);
+	if (level == 2)
+		return fastlz2_compress(hash_table, input, length, output);
+
+	return 0;
+}
+
+#else /* !defined(FASTLZ_COMPRESSOR) */
+
+static FASTLZ_INLINE int FASTLZ_COMPRESSOR(unsigned char *hash_table,
+					   const void *input, int length,
+					   void *output)
+{
+	const unsigned char *ip = (const unsigned char *) input;
+	const unsigned char *ip_bound = ip + length - 2;
+	const unsigned char *ip_limit = ip + length - 12;
+	unsigned char *op = (unsigned char *) output;
+
+	const unsigned char **htab = (const unsigned char **)hash_table;
+	const unsigned char **hslot;
+	unsigned int hval;
+
+	unsigned int copy;
+
+	/* sanity check */
+	if (FASTLZ_UNEXPECT_CONDITIONAL(length < 4)) {
+		if (length) {
+			/* create literal copy only */
+			*op++ = length - 1;
+			ip_bound++;
+			while (ip <= ip_bound)
+				*op++ = *ip++;
+			return length + 1;
+		} else
+			return 0;
+	}
+
+	/* initializes hash table */
+	for (hslot = htab; hslot < htab + FASTLZ_HASH_SIZE; hslot++)
+		*hslot = ip;
+
+	/* we start with literal copy */
+	copy = 2;
+	*op++ = MAX_COPY - 1;
+	*op++ = *ip++;
+	*op++ = *ip++;
+
+	/* main loop */
+	while (FASTLZ_EXPECT_CONDITIONAL(ip < ip_limit)) {
+		const unsigned char *ref;
+		unsigned int distance;
+
+		/* minimum match length */
+		unsigned int len = 3;
+
+		/* comparison starting-point */
+		const unsigned char *anchor = ip;
+
+		/* check for a run */
+#if FASTLZ_LEVEL == 2
+		if (ip[0] == ip[-1] &&
+		    FASTLZ_READU16(ip - 1) == FASTLZ_READU16(ip + 1)) {
+			distance = 1;
+			ip += 3;
+			ref = anchor - 1 + 3;
+			goto match;
+		}
+#endif
+
+		/* find potential match */
+		HASH_FUNCTION(hval, ip);
+		hslot = htab + hval;
+		ref = htab[hval];
+
+		/* calculate distance to the match */
+		distance = anchor - ref;
+
+		/* update hash table */
+		*hslot = anchor;
+
+		if (!ref)
+			goto literal;
+		/* is this a match? check the first 3 bytes */
+		if (distance == 0 ||
+#if FASTLZ_LEVEL == 1
+				(distance >= MAX_DISTANCE) ||
+#else
+				(distance >= MAX_FARDISTANCE) ||
+#endif
+				*ref++ != *ip++ || *ref++ != *ip++ ||
+				*ref++ != *ip++)
+			goto literal;
+
+#if FASTLZ_LEVEL == 2
+		/* far, needs at least 5-byte match */
+		if (distance >= MAX_DISTANCE) {
+			if (*ip++ != *ref++ || *ip++ != *ref++)
+				goto literal;
+			len += 2;
+		}
+
+match:
+#endif
+
+		/* last matched byte */
+		ip = anchor + len;
+
+		/* distance is biased */
+		distance--;
+
+		if (!distance) {
+			/* zero distance means a run */
+			unsigned char x = ip[-1];
+			while (ip < ip_bound)
+				if (*ref++ != x)
+					break;
+				else
+					ip++;
+		} else
+			for (;;) {
+				/* safe because the outer check
+				 * against ip limit */
+				if (*ref++ != *ip++)
+					break;
+				if (*ref++ != *ip++)
+					break;
+				if (*ref++ != *ip++)
+					break;
+				if (*ref++ != *ip++)
+					break;
+				if (*ref++ != *ip++)
+					break;
+				if (*ref++ != *ip++)
+					break;
+				if (*ref++ != *ip++)
+					break;
+				if (*ref++ != *ip++)
+					break;
+				while (ip < ip_bound)
+					if (*ref++ != *ip++)
+						break;
+				break;
+			}
+
+		/* if we have copied something, adjust the copy count */
+		if (copy)
+			/* copy is biased, '0' means 1 byte copy */
+			*(op - copy - 1) = copy - 1;
+		else
+			/* back, to overwrite the copy count */
+			op--;
+
+		/* reset literal counter */
+		copy = 0;
+
+		/* length is biased, '1' means a match of 3 bytes */
+		ip -= 3;
+		len = ip - anchor;
+
+		/* encode the match */
+#if FASTLZ_LEVEL == 2
+		if (distance < MAX_DISTANCE) {
+			if (len < 7) {
+				*op++ = (len << 5) + (distance >> 8);
+				*op++ = (distance & 255);
+			} else {
+				*op++ = (7 << 5) + (distance >> 8);
+				for (len -= 7; len >= 255; len -= 255)
+					*op++ = 255;
+				*op++ = len;
+				*op++ = (distance & 255);
+			}
+		} else {
+			/* far away, but not yet in the another galaxy... */
+			if (len < 7) {
+				distance -= MAX_DISTANCE;
+				*op++ = (len << 5) + 31;
+				*op++ = 255;
+				*op++ = distance >> 8;
+				*op++ = distance & 255;
+			} else {
+				distance -= MAX_DISTANCE;
+				*op++ = (7 << 5) + 31;
+				for (len -= 7; len >= 255; len -= 255)
+					*op++ = 255;
+				*op++ = len;
+				*op++ = 255;
+				*op++ = distance >> 8;
+				*op++ = distance & 255;
+			}
+		}
+#else
+
+		if (FASTLZ_UNEXPECT_CONDITIONAL(len > MAX_LEN - 2))
+			while (len > MAX_LEN - 2) {
+				*op++ = (7 << 5) + (distance >> 8);
+				*op++ = MAX_LEN - 2 - 7 - 2;
+				*op++ = (distance & 255);
+				len -= MAX_LEN - 2;
+			}
+
+		if (len < 7) {
+			*op++ = (len << 5) + (distance >> 8);
+			*op++ = (distance & 255);
+		} else {
+			*op++ = (7 << 5) + (distance >> 8);
+			*op++ = len - 7;
+			*op++ = (distance & 255);
+		}
+#endif
+
+		/* update the hash at match boundary */
+		HASH_FUNCTION(hval, ip);
+		htab[hval] = ip++;
+		HASH_FUNCTION(hval, ip);
+		htab[hval] = ip++;
+
+		/* assuming literal copy */
+		*op++ = MAX_COPY - 1;
+
+		continue;
+
+literal:
+		*op++ = *anchor++;
+		ip = anchor;
+		copy++;
+		if (FASTLZ_UNEXPECT_CONDITIONAL(copy == MAX_COPY)) {
+			copy = 0;
+			*op++ = MAX_COPY - 1;
+		}
+	}
+
+	/* left-over as literal copy */
+	ip_bound++;
+	while (ip <= ip_bound) {
+		*op++ = *ip++;
+		copy++;
+		if (copy == MAX_COPY) {
+			copy = 0;
+			*op++ = MAX_COPY - 1;
+		}
+	}
+
+	/* if we have copied something, adjust the copy length */
+	if (copy)
+		*(op - copy - 1) = copy - 1;
+	else
+		op--;
+
+#if FASTLZ_LEVEL == 2
+	/* marker for fastlz2 */
+	*(unsigned char *)output |= (1 << 5);
+#endif
+
+	return op - (unsigned char *)output;
+}
+#endif /* !defined(FASTLZ_COMPRESSOR) */
diff --git a/drivers/net/ethernet/chelsio/cxgb4/fastlz.h b/drivers/net/ethernet/chelsio/cxgb4/fastlz.h
new file mode 100644
index 00000000..c3db989b
--- /dev/null
+++ b/drivers/net/ethernet/chelsio/cxgb4/fastlz.h
@@ -0,0 +1,88 @@
+/*
+   FastLZ - lightning-fast lossless compression library
+
+   Copyright (C) 2007 Ariya Hidayat (ariya@kde.org)
+   Copyright (C) 2006 Ariya Hidayat (ariya@kde.org)
+   Copyright (C) 2005 Ariya Hidayat (ariya@kde.org)
+   Copyright (C) 2017 Chelsio Communications
+
+   Permission is hereby granted, free of charge, to any person obtaining a copy
+   of this software and associated documentation files (the "Software"), to deal
+   in the Software without restriction, including without limitation the rights
+   to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+   copies of the Software, and to permit persons to whom the Software is
+   furnished to do so, subject to the following conditions:
+
+   The above copyright notice and this permission notice shall be included in
+   all copies or substantial portions of the Software.
+
+   THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+   IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+   FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+   AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+   LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+   OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+   THE SOFTWARE.
+   */
+
+#ifndef FASTLZ_H
+#define FASTLZ_H
+
+#define FASTLZ_VERSION 0x000100
+
+#define FASTLZ_VERSION_MAJOR	 0
+#define FASTLZ_VERSION_MINOR	 0
+#define FASTLZ_VERSION_REVISION  0
+
+#define FASTLZ_VERSION_STRING "0.1.0"
+
+#if defined __cplusplus
+extern "C" {
+#endif
+
+	/**
+	  Compress a block of data in the input buffer and returns the size of
+	  compressed block. The size of input buffer is specified by length. The
+	  minimum input buffer size is 16.
+
+	  The output buffer must be at least 5% larger than the input buffer
+	  and can not be smaller than 66 bytes.
+
+	  If the input is not compressible, the return value might be larger
+	  than length (input buffer size).
+
+	  The input buffer and the output buffer can not overlap.
+	  */
+
+	int fastlz_compress(unsigned char *hash_table, const void *input,
+			    int length, void *output);
+	/**
+	  Compress a block of data in the input buffer and returns the size of
+	  compressed block. The size of input buffer is specified by length. The
+	  minimum input buffer size is 16.
+
+	  The output buffer must be at least 5% larger than the input buffer
+	  and can not be smaller than 66 bytes.
+
+	  If the input is not compressible, the return value might be larger
+	  than length (input buffer size).
+
+	  The input buffer and the output buffer can not overlap.
+
+	  Compression level can be specified in parameter level. At the moment,
+	  only level 1 and level 2 are supported.
+	  Level 1 is the fastest compression and generally useful for short
+	  data.
+	  Level 2 is slightly slower but it gives better compression ratio.
+
+	  Note that the compressed data, regardless of the level, can always be
+	  decompressed using the function fastlz_decompress above.
+	  */
+
+	int fastlz_compress_level(unsigned char *hash_table, int level,
+				  const void *input, int length,
+				  void *output);
+#if defined __cplusplus
+}
+#endif
+#endif /* FASTLZ_H */
diff --git a/drivers/net/ethernet/chelsio/cxgb4/fastlz_api.c b/drivers/net/ethernet/chelsio/cxgb4/fastlz_api.c
new file mode 100644
index 00000000..dbf78f7f
--- /dev/null
+++ b/drivers/net/ethernet/chelsio/cxgb4/fastlz_api.c
@@ -0,0 +1,176 @@
+/*
+ *  Copyright (C) 2017 Chelsio Communications.  All rights reserved.
+ *
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms and conditions of the GNU General Public License,
+ *  version 2, as published by the Free Software Foundation.
+ *
+ *  This program is distributed in the hope it will be useful, but WITHOUT
+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ *  more details.
+ *
+ *  The full GNU General Public License is included in this distribution in
+ *  the file called "COPYING".
+ *
+ */
+
+#include "cxgb4.h"
+#include "fastlz.h"
+#include "fastlz_common.h"
+#include "cudbg_if.h"
+#include "cudbg_lib_common.h"
+
+unsigned char sixpack_magic[8] = {137, '6', 'P', 'K', 13, 10, 26, 10};
+
+static int write_to_buf(void *out_buf, u32 out_buf_size, u32 *offset,
+			void *in_buf, u32 in_buf_size)
+{
+	memcpy(((char *)out_buf) + *offset, in_buf, in_buf_size);
+	*offset = *offset + in_buf_size;
+	return 0;
+}
+
+static int write_magic(struct cudbg_buffer *_out_buff)
+{
+	return write_to_buf(_out_buff->data, _out_buff->size,
+			    &_out_buff->offset, sixpack_magic, 8);
+}
+
+static int write_chunk_header(struct cudbg_buffer *_outbuf, int id, int options,
+			      unsigned long size, unsigned long checksum,
+			      unsigned long extra)
+{
+	unsigned char buffer[CUDBG_CHUNK_BUF_LEN];
+
+	buffer[0] = id & 255;
+	buffer[1] = (unsigned char)(id >> 8);
+	buffer[2] = options & 255;
+	buffer[3] = (unsigned char)(options >> 8);
+	buffer[4] = size & 255;
+	buffer[5] = (size >> 8) & 255;
+	buffer[6] = (size >> 16) & 255;
+	buffer[7] = (size >> 24) & 255;
+	buffer[8] = checksum & 255;
+	buffer[9] = (checksum >> 8) & 255;
+	buffer[10] = (checksum >> 16) & 255;
+	buffer[11] = (checksum >> 24) & 255;
+	buffer[12] = extra & 255;
+	buffer[13] = (extra >> 8) & 255;
+	buffer[14] = (extra >> 16) & 255;
+	buffer[15] = (extra >> 24) & 255;
+
+	return write_to_buf(_outbuf->data, _outbuf->size, &_outbuf->offset,
+			    buffer, 16);
+}
+
+int cudbg_write_compression_hdr(struct cudbg_init *pdbg_init,
+				struct cudbg_buffer *pin_buff,
+				struct cudbg_buffer *pout_buff)
+{
+	struct cudbg_buffer temp_buff = { 0 };
+	unsigned long fsize = pin_buff->size;
+	char *shown_name = "abc";
+	unsigned long checksum;
+	unsigned char *buffer;
+	int rc;
+
+	cudbg_get_compress_buff(pdbg_init, pin_buff, &temp_buff);
+	buffer = (unsigned char *)temp_buff.data;
+
+	rc = write_magic(pout_buff);
+	if (rc)
+		return rc;
+
+	/* chunk for File Entry */
+	buffer[0] = fsize & 255;
+	buffer[1] = (fsize >> 8) & 255;
+	buffer[2] = (fsize >> 16) & 255;
+	buffer[3] = (fsize >> 24) & 255;
+	buffer[4] = 0;
+	buffer[5] = 0;
+	buffer[6] = 0;
+	buffer[7] = 0;
+	buffer[8] = (strlen(shown_name) + 1) & 255;
+	buffer[9] = (unsigned char)((strlen(shown_name) + 1) >> 8);
+	checksum = 1L;
+	checksum = update_adler32(checksum, buffer, 10);
+	checksum = update_adler32(checksum, shown_name,
+				  (int)strlen(shown_name) + 1);
+
+	rc = write_chunk_header(pout_buff, 1, 0,
+				10 + (unsigned long)strlen(shown_name)+ 1,
+				checksum, 0);
+	if (rc)
+		return rc;
+
+	rc = write_to_buf(pout_buff->data, pout_buff->size,
+			  &pout_buff->offset, buffer, 10);
+	if (rc)
+		return rc;
+
+	rc = write_to_buf(pout_buff->data, pout_buff->size,
+			   &pout_buff->offset, shown_name,
+			   (u32)strlen(shown_name) + 1);
+	if (rc)
+		return rc;
+
+	return rc;
+}
+
+int cudbg_compress_buff(struct cudbg_init *pdbg_init,
+			struct cudbg_buffer *pin_buff,
+			struct cudbg_buffer *pout_buff)
+{
+	struct cudbg_buffer temp_buff = { 0 };
+	int chunk_size, level = 2, rc = 0;
+	int compress_method = 1;
+	unsigned int bytes_read;
+	unsigned long checksum;
+	unsigned char *result;
+
+	cudbg_get_compress_buff(pdbg_init, pin_buff, &temp_buff);
+	result = (unsigned char *)temp_buff.data;
+
+	bytes_read = pin_buff->size;
+	if (bytes_read < 32)
+		compress_method = 0;
+
+	switch (compress_method) {
+	case 1:
+		chunk_size = fastlz_compress_level(pdbg_init->hash_table,
+						   level,
+						   pin_buff->data,
+						   bytes_read, result);
+		checksum = update_adler32(1L, result, chunk_size);
+		rc = write_chunk_header(pout_buff, 17, 1, chunk_size, checksum,
+					bytes_read);
+		if (rc)
+			return rc;
+
+		rc = write_to_buf(pout_buff->data, pout_buff->size,
+				  &pout_buff->offset, result, chunk_size);
+		if (rc)
+			return rc;
+		break;
+
+		/* uncompressed, also fallback method */
+	case 0:
+	default:
+		memcpy(result, pin_buff->data, bytes_read);
+		checksum = update_adler32(1L, result, bytes_read);
+		rc = write_chunk_header(pout_buff, 17, 0, bytes_read, checksum,
+					bytes_read);
+		if (rc)
+			return rc;
+
+		rc = write_to_buf(pout_buff->data, pout_buff->size,
+				  &pout_buff->offset, result,
+				  bytes_read);
+		if (rc)
+			return rc;
+		break;
+	}
+
+	return rc;
+}
diff --git a/drivers/net/ethernet/chelsio/cxgb4/fastlz_common.h b/drivers/net/ethernet/chelsio/cxgb4/fastlz_common.h
new file mode 100644
index 00000000..19e0e45a
--- /dev/null
+++ b/drivers/net/ethernet/chelsio/cxgb4/fastlz_common.h
@@ -0,0 +1,134 @@
+/*
+   FastLZ - lightning-fast lossless compression library
+
+   Copyright (C) 2007 Ariya Hidayat (ariya@kde.org)
+   Copyright (C) 2006 Ariya Hidayat (ariya@kde.org)
+   Copyright (C) 2005 Ariya Hidayat (ariya@kde.org)
+   Copyright (C) 2017 Chelsio Communications
+
+   Permission is hereby granted, free of charge, to any person obtaining a copy
+   of this software and associated documentation files (the "Software"), to deal
+   in the Software without restriction, including without limitation the rights
+   to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+   copies of the Software, and to permit persons to whom the Software is
+   furnished to do so, subject to the following conditions:
+
+   The above copyright notice and this permission notice shall be included in
+   all copies or substantial portions of the Software.
+
+   THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+   IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+   FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+   AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+   LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+   OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+   THE SOFTWARE.
+   */
+
+#ifndef __FASTLZ_COMMON_H__
+#define __FASTLZ_COMMON_H__
+
+#define FASTLZ_HASH_LOG  13
+#define FASTLZ_HASH_SIZE (1 << FASTLZ_HASH_LOG)
+#define FASTLZ_HASH_MASK  (FASTLZ_HASH_SIZE - 1)
+
+/*
+ * Always check for bound when decompressing.
+ * Generally it is best to leave it defined.
+ */
+#define FASTLZ_SAFE
+
+/*
+ * Give hints to the compiler for branch prediction optimization.
+ */
+#define FASTLZ_EXPECT_CONDITIONAL(c)	(__builtin_expect((c), 1))
+#define FASTLZ_UNEXPECT_CONDITIONAL(c)	(__builtin_expect((c), 0))
+
+/*
+ * Use inlined functions for supported systems.
+ */
+#define FASTLZ_INLINE inline
+
+/*
+ * Prevent accessing more than 8-bit at once, except on x86 architectures.
+ */
+#if !defined(FASTLZ_STRICT_ALIGN)
+#define FASTLZ_STRICT_ALIGN
+#if defined(__i386__) || defined(__386)  /* GNU C, Sun Studio */
+#undef FASTLZ_STRICT_ALIGN
+#elif defined(__i486__) || defined(__i586__) || defined(__i686__) /* GNU C */
+#undef FASTLZ_STRICT_ALIGN
+#elif defined(_M_IX86) /* Intel, MSVC */
+#undef FASTLZ_STRICT_ALIGN
+#elif defined(__386)
+#undef FASTLZ_STRICT_ALIGN
+#elif defined(_X86_) /* MinGW */
+#undef FASTLZ_STRICT_ALIGN
+#elif defined(__I86__) /* Digital Mars */
+#undef FASTLZ_STRICT_ALIGN
+#endif
+#endif
+
+/*
+ * FIXME: use preprocessor magic to set this on different platforms!
+ */
+
+#define MAX_COPY       32
+#define MAX_LEN       264  /* 256 + 8 */
+#define MAX_DISTANCE 8192
+
+#if !defined(FASTLZ_STRICT_ALIGN)
+#define FASTLZ_READU16(p) (*((const unsigned short *)(p)))
+#else
+#define FASTLZ_READU16(p) ((p)[0] | (p)[1]<<8)
+#endif
+
+#define HASH_FUNCTION(v, p) {\
+				v = FASTLZ_READU16(p);\
+				v ^= FASTLZ_READU16(p + 1)^\
+				     (v>>(16 - FASTLZ_HASH_LOG));\
+				v &= FASTLZ_HASH_MASK;\
+			    }
+
+extern unsigned char sixpack_magic[8];
+
+#define CUDBG_BLOCK_SIZE      (63*1024)
+#define CUDBG_CHUNK_BUF_LEN   16
+#define CUDBG_MIN_COMPR_LEN   32	/*min data length for applying compression*/
+
+/* for Adler-32 checksum algorithm, see RFC 1950 Section 8.2 */
+
+#define ADLER32_BASE 65521
+
+static inline unsigned long update_adler32(unsigned long checksum,
+					   const void *buf, int len)
+{
+	const unsigned char *ptr = (const unsigned char *)buf;
+	unsigned long s1 = checksum & 0xffff;
+	unsigned long s2 = (checksum >> 16) & 0xffff;
+
+	while (len > 0) {
+		unsigned k = len < 5552 ? len : 5552;
+		len -= k;
+
+		while (k >= 8) {
+			s1 += *ptr++; s2 += s1;
+			s1 += *ptr++; s2 += s1;
+			s1 += *ptr++; s2 += s1;
+			s1 += *ptr++; s2 += s1;
+			s1 += *ptr++; s2 += s1;
+			s1 += *ptr++; s2 += s1;
+			s1 += *ptr++; s2 += s1;
+			s1 += *ptr++; s2 += s1;
+			k -= 8;
+		}
+
+		while (k-- > 0) {
+			s1 += *ptr++; s2 += s1;
+		}
+		s1 = s1 % ADLER32_BASE;
+		s2 = s2 % ADLER32_BASE;
+	}
+	return (s2 << 16) + s1;
+}
+#endif /* __FASTLZ_COMMON_H__ */
-- 
2.14.1

